{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f21f170",
   "metadata": {},
   "source": [
    "GOLF SHOT SWING RECOGNITION USING OPTICAL FLOW."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b2729f6",
   "metadata": {},
   "source": [
    "Implementing Gunnar Farneback based Optical Flow for trajectory estimation.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efb846ac",
   "metadata": {},
   "source": [
    "Implementing Morphological Filter on image frame contributing trajectory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "be4cb542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Path to folder with videos\n",
    "videos_folder = './dataset'\n",
    "\n",
    "# Path to folder where optical flow images will be saved\n",
    "optical_flow_folder_gf = './optical_flow_images_gf'\n",
    "optical_flow_folder_lk = './optical_flow_images_lk'\n",
    "\n",
    "# Loop through all videos in the folder\n",
    "for video_name in os.listdir(videos_folder):\n",
    "    \n",
    "    # Get the label of the video from its name (assuming that the label is the first word in the file name)\n",
    "    label = video_name.split('_')[0]\n",
    "    bgSubtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "    # Open the video file\n",
    "    video_path = os.path.join(videos_folder, video_name)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Read the first frame\n",
    "    ret, frame1 = cap.read()\n",
    "    i = 0\n",
    "    # Loop through the rest of the frames\n",
    "    while True:\n",
    "        \n",
    "        # Read the next frame\n",
    "        ret, frame2 = cap.read()\n",
    "        \n",
    "        # If there are no more frames, break out of the loop\n",
    "        if not ret:\n",
    "            break\n",
    "        # Convert frames to grayscale\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Calculate optical flow using Farnback algorithm\n",
    "        flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        # Convert optical flow to image format\n",
    "        hsv = np.zeros((frame1.shape[0], frame1.shape[1], 3), dtype=np.uint8)\n",
    "        \n",
    "        hsv[...,1] = 255\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        hsv[...,0] = ang*180/np.pi/2\n",
    "        hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "        optical_flow_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "        # Save the optical flow image with the corresponding label in the optical flow folder\n",
    "        optical_flow_name = f'{label}_{str(i).zfill(4)}.png'\n",
    "        i=i+1\n",
    "        optical_flow_path = os.path.join(optical_flow_folder_gf, optical_flow_name)\n",
    "        cv2.imwrite(optical_flow_path, optical_flow_image)\n",
    "        \n",
    "        # Apply background subtraction to frame\n",
    "        fgMask = bgSubtractor.apply(frame2)\n",
    "\n",
    "        # Apply morphological operations to reduce noise and fill gaps\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        \n",
    "        # Save the optical flow image with the corresponding label in the optical flow folder\n",
    "        optical_flow_name = f'{label}_{str(i).zfill(4)}.png'\n",
    "        i=i+1\n",
    "        optical_flow_path = os.path.join(optical_flow_folder_lk, optical_flow_name)\n",
    "        cv2.imwrite(optical_flow_path, fgMask)\n",
    "\n",
    "\n",
    "        # Update the current frame\n",
    "        frame1 = frame2\n",
    "        \n",
    "    # Release the video capture object\n",
    "    cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a0174c7",
   "metadata": {},
   "source": [
    "Define Function for extraction of HOG features from Gunnar Farneback Images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bdfa2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    # define the HOG parameters\n",
    "    orientations = 9\n",
    "    pixels_per_cell = (16, 16)\n",
    "    cells_per_block = (2, 2)\n",
    "    \n",
    "    # compute the HOG features for the image\n",
    "    features = hog(image, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=False, transform_sqrt=True)\n",
    "    print('\\n')\n",
    "    # return the features as a 1D NumPy array\n",
    "    return features.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f64cfa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "csv_file_path = './features_back.csv'\n",
    "with open(csv_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the header row with feature names\n",
    "    num_bins = 10\n",
    "    header = ['Mean', 'Standard Deviation', 'Variance','Label'] + ['Bin {}'.format(i) for i in range(num_bins)] + ['Sum HOG', 'Mean HOG', 'Standard Deviation HOG', 'Variance HOG'] + ['HOG Hist {}'.format(i) for i in range(0,10)]\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for image in os.listdir('./optical_flow_images_gf'):\n",
    "        image_path = os.path.join('./optical_flow_images_gf', image)\n",
    "\n",
    "        # Load the preprocessed optical flow image\n",
    "        optical_flow = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Calculate the mean, standard deviation, and variance of the optical flow image\n",
    "        try:\n",
    "            mean = np.mean(optical_flow)\n",
    "            std = np.std(optical_flow)\n",
    "            var = np.var(optical_flow)\n",
    "        except:\n",
    "            continue\n",
    "        # Calculate the histogram of the optical flow image\n",
    "        hist, bins = np.histogram(optical_flow, bins=num_bins, range=(-10, 10))\n",
    "        hist = hist.tolist()\n",
    "        \n",
    "        h=np.unique(extract_hog_features(optical_flow))\n",
    "        sum_hog=np.sum(h)\n",
    "        mean_hog=np.mean(h)\n",
    "        std_hog=np.std(h)\n",
    "        var_hog=np.var(h)\n",
    "        hog_hist=np.zeros(10)\n",
    "        for i in h:\n",
    "            if i>0.0 and i<0.1:\n",
    "                hog_hist[0]+=1\n",
    "            elif i>0.1 and i<0.2:\n",
    "                hog_hist[1]+=1\n",
    "            elif i>0.2 and i<0.3:\n",
    "                hog_hist[2]+=1\n",
    "            elif i>0.3 and i<0.4:\n",
    "                hog_hist[3]+=1\n",
    "            elif i>0.4 and i<0.5:\n",
    "                hog_hist[4]+=1\n",
    "            elif i>0.5 and i<0.6:\n",
    "                hog_hist[5]+=1\n",
    "            elif i>0.6 and i<0.7:\n",
    "                hog_hist[6]+=1\n",
    "            elif i>0.7 and i<0.8:\n",
    "                hog_hist[7]+=1\n",
    "            elif i>0.8 and i<0.9:\n",
    "                hog_hist[8]+=1\n",
    "            else:\n",
    "                hog_hist[9]+=1\n",
    "        hog_hist=hog_hist.tolist()        \n",
    "        \n",
    "        # Append the features to the CSV file\n",
    "        writer.writerow([mean, std, var,image.split('_')[0]] + hist + [sum_hog, mean_hog, std_hog, var_hog] + hog_hist )\n",
    "        # Print the calculated features\n",
    "        #print('Mean: {:.2f}'.format(mean))\n",
    "        #print('Standard Deviation: {:.2f}'.format(std))\n",
    "        #print('Variance: {:.2f}'.format(var))\n",
    "        #print('Histogram: {}'.format(hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182eb7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Mean  Standard Deviation  Variance   Label  Bin 0  Bin 1  Bin 2  \\\n",
      "0     0.086395            0.296581  0.119031    back      0      0      0   \n",
      "1     0.050625            0.173118  0.051290    back      0      0      0   \n",
      "2     0.119815            0.248251  0.089423    back      0      0      0   \n",
      "3     0.129642            0.341006  0.149754    back      0      0      0   \n",
      "4     0.060640            0.208397  0.067999    back      0      0      0   \n",
      "...        ...                 ...       ...     ...    ...    ...    ...   \n",
      "1053  0.230066            0.320413  0.135095  follow      0      0      0   \n",
      "1054  0.124572            0.198407  0.063052  follow      0      0      0   \n",
      "1055  0.160668            0.201009  0.064324  follow      0      0      0   \n",
      "1056  0.119285            0.169203  0.049566  follow      0      0      0   \n",
      "1057  0.386801            0.371797  0.173019  follow      0      0      0   \n",
      "\n",
      "      Bin 3  Bin 4     Bin 5  ...  HOG Hist 0  HOG Hist 1  HOG Hist 2  \\\n",
      "0         0      0  0.912713  ...    0.150720    0.127582    0.177538   \n",
      "1         0      0  0.943639  ...    0.104055    0.085588    0.118847   \n",
      "2         0      0  0.879466  ...    0.183288    0.159566    0.219491   \n",
      "3         0      0  0.889600  ...    0.162316    0.142062    0.189308   \n",
      "4         0      0  0.939477  ...    0.101706    0.082844    0.105927   \n",
      "...     ...    ...       ...  ...         ...         ...         ...   \n",
      "1053      0      0  0.772940  ...    0.306705    0.326068    0.334362   \n",
      "1054      0      0  0.840216  ...    0.218379    0.188756    0.219857   \n",
      "1055      0      0  0.794087  ...    0.267045    0.249854    0.279803   \n",
      "1056      0      0  0.835342  ...    0.232846    0.196835    0.248731   \n",
      "1057      0      0  0.569413  ...    0.448070    0.461195    0.465868   \n",
      "\n",
      "      HOG Hist 3  HOG Hist 4  HOG Hist 5  HOG Hist 6  HOG Hist 7  HOG Hist 8  \\\n",
      "0       0.440529    0.516426    0.709524    0.381818    0.157895    0.166667   \n",
      "1       0.224670    0.340342    0.433333    0.381818    0.157895    0.000000   \n",
      "2       0.449339    0.374507    0.323810    0.290909    0.263158    0.000000   \n",
      "3       0.378516    0.300920    0.471429    0.236364    0.157895    0.000000   \n",
      "4       0.177228    0.287779    0.366667    0.345455    0.210526    0.166667   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "1053    0.498475    0.448095    0.504762    0.545455    0.368421    0.166667   \n",
      "1054    0.205015    0.164258    0.209524    0.236364    0.157895    0.166667   \n",
      "1055    0.307692    0.374507    0.466667    0.254545    0.368421    0.666667   \n",
      "1056    0.207726    0.122208    0.133333    0.272727    0.105263    0.166667   \n",
      "1057    0.228397    0.202365    0.261905    0.327273    0.210526    0.166667   \n",
      "\n",
      "      HOG Hist 9  \n",
      "0            0.4  \n",
      "1            0.2  \n",
      "2            0.2  \n",
      "3            0.2  \n",
      "4            0.2  \n",
      "...          ...  \n",
      "1053         0.2  \n",
      "1054         0.4  \n",
      "1055         0.2  \n",
      "1056         0.2  \n",
      "1057         0.6  \n",
      "\n",
      "[1058 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Read CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv('./features_back.csv')\n",
    "\n",
    "# Define the columns to be normalized\n",
    "cols_to_norm = ['Mean', 'Standard Deviation', 'Variance', 'Bin 5', 'Bin 6','Bin 7', 'Bin 8','Bin 9','Sum HOG', 'Mean HOG', 'Standard Deviation HOG', 'HOG Hist 0', 'HOG Hist 1', 'HOG Hist 2', 'HOG Hist 3', 'HOG Hist 4', 'HOG Hist 5','HOG Hist 6','HOG Hist 7','HOG Hist 8','HOG Hist 9']\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the selected columns using the scaler\n",
    "df[cols_to_norm] = scaler.fit_transform(df[cols_to_norm])\n",
    "\n",
    "df.to_csv('./features_back.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b72a3e7",
   "metadata": {},
   "source": [
    "SIFT feature extraction from morphological image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63a76845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "csv_file_path = './features_back_lk.csv'\n",
    "with open(csv_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    header = ['SIFT {}'.format(i) for i in range(0,128)]\n",
    "    writer.writerow(header)\n",
    "    for image in os.listdir('./optical_flow_images_lk'):\n",
    "        image_path = os.path.join('./optical_flow_images_lk', image)\n",
    "        label=image.split('_')[0]\n",
    "        # Load the preprocessed optical flow image\n",
    "        optical_flow = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        #initialise sift descriptor\n",
    "        sift = cv2.SIFT_create()\n",
    "        keypoints, descriptors = sift.detectAndCompute(optical_flow, None)\n",
    "        # sift_image = cv2.drawKeypoints(gray, keypoints, img)\n",
    "        # print(type(descriptors))\n",
    "        try:\n",
    "            descriptors=descriptors.T\n",
    "            # pca = PCA(n_components=0.95)\n",
    "            # # Fit the transformer to the data and transform the data\n",
    "            # descriptors = pca.fit_transform(descriptors)\n",
    "            # # Reshape the descriptors array into a 1D array\n",
    "            descriptors_1d = descriptors.reshape(-1)\n",
    "            descriptors_1d = descriptors_1d[:128]\n",
    "        except:\n",
    "            descriptors_1d=np.zeros(128)\n",
    "        # Append the new feature to an existing row\n",
    "        writer.writerow(descriptors_1d.tolist())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd22221f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SIFT 0    SIFT 1    SIFT 2    SIFT 3    SIFT 4    SIFT 5    SIFT 6  \\\n",
      "0     0.866106  0.632695  0.461859  0.449646  0.549696  0.380122  0.466683   \n",
      "1     0.610998  0.351353  0.403890  0.703854  0.434921  0.662251  0.280480   \n",
      "2     0.489854  0.386070  0.580198  0.564362  0.422432  0.535476  0.368421   \n",
      "3     0.604521  0.361964  0.545194  0.603571  0.408072  0.278031  0.511354   \n",
      "4     0.601887  0.452448  0.593554  0.625858  0.382814  0.494532  0.723068   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1053  0.579201  0.480422  0.400291  0.560080  0.737868  0.522182  0.526370   \n",
      "1054  0.545510  0.462191  0.614856  0.390300  0.414835  0.538223  0.435255   \n",
      "1055  0.554743  0.598361  0.572004  0.601054  0.408230  0.531984  0.379482   \n",
      "1056  0.541040  0.457218  0.336172  0.560201  0.707961  0.501126  0.371671   \n",
      "1057  0.459604  0.489164  0.570025  0.486173  0.726231  0.540978  0.285900   \n",
      "\n",
      "        SIFT 7    SIFT 8    SIFT 9  ...  SIFT 118  SIFT 119  SIFT 120  \\\n",
      "0     0.519538  0.536483  0.535178  ...  0.638106  0.521131  0.523139   \n",
      "1     0.546235  0.622958  0.511727  ...  0.554131  0.600674  0.415207   \n",
      "2     0.567129  0.571550  0.659185  ...  0.772716  0.618334  0.502035   \n",
      "3     0.421866  0.506700  0.331679  ...  0.586724  0.508909  0.550928   \n",
      "4     0.497431  0.430395  0.419310  ...  0.606490  0.552212  0.478968   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1053  0.643591  0.596341  0.498700  ...  0.631382  0.561805  0.604375   \n",
      "1054  0.515780  0.491043  0.409217  ...  0.647317  0.580417  0.572994   \n",
      "1055  0.512772  0.453258  0.492166  ...  0.494715  0.555289  0.508629   \n",
      "1056  0.495255  0.506028  0.542779  ...  0.713982  0.557807  0.494083   \n",
      "1057  0.560362  0.617546  0.481290  ...  0.590987  0.497033  0.443227   \n",
      "\n",
      "      SIFT 121  SIFT 122  SIFT 123  SIFT 124  SIFT 125  SIFT 126  SIFT 127  \n",
      "0     0.506598  0.478234  0.533687  0.587852  0.484758  0.532171  0.409251  \n",
      "1     0.459372  0.691019  0.480397  0.607641  0.491163  0.499795  0.406104  \n",
      "2     0.490950  0.494832  0.587406  0.633102  0.469670  0.504707  0.528085  \n",
      "3     0.529031  0.432227  0.489039  0.575721  0.498157  0.315773  0.206726  \n",
      "4     0.490766  0.481694  0.456326  0.607098  0.460579  0.563521  0.449717  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1053  0.421449  0.478252  0.559365  0.555118  0.406045  0.244593  0.271344  \n",
      "1054  0.333864  0.541661  0.568256  0.587075  0.317193  0.531275  0.479822  \n",
      "1055  0.460855  0.392163  0.607213  0.386166  0.569145  0.483764  0.357357  \n",
      "1056  0.565923  0.490389  0.551897  0.687420  0.443465  0.524537  0.391414  \n",
      "1057  0.413475  0.527457  0.504581  0.582591  0.442052  0.513215  0.380696  \n",
      "\n",
      "[1058 rows x 128 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Read CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv('./features_back_lk.csv')\n",
    "\n",
    "# Define the columns to be normalized\n",
    "cols_to_norm = ['SIFT {}'.format(i) for i in range(0,128)]\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the selected columns using the scaler\n",
    "df[cols_to_norm] = scaler.fit_transform(df[cols_to_norm])\n",
    "\n",
    "df.to_csv('./features_back_lk.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d602564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Define the paths to the CSV files\n",
    "csv_path_1 = \"./features_back.csv\"\n",
    "csv_path_2 = \"./features_back_lk.csv\"\n",
    "\n",
    "# Read the CSV files into separate pandas DataFrames\n",
    "df1 = pd.read_csv(csv_path_1)\n",
    "df2 = pd.read_csv(csv_path_2)\n",
    "# print(df1.columns.tolist())\n",
    "# print(df2.columns.tolist())\n",
    "# print(df1.loc[0].tolist()+df2.loc[0].tolist())\n",
    "csv_file_path = './features.csv'\n",
    "with open(csv_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    header = df1.columns.tolist()+df2.columns.tolist()\n",
    "    writer.writerow(header)\n",
    "    row=[]\n",
    "    for i in range(1058):\n",
    "        row=df1.loc[i].tolist()+df2.loc[i].tolist()\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43727ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Mean  Standard Deviation   Variance   Label    Bin 5  Bin 6  Bin 7  \\\n",
      "0     0.556674            4.696250  22.054761    back  1094022  31458  15121   \n",
      "1     0.359380            3.186641  10.154681    back  1114348  23904  10572   \n",
      "2     0.741009            4.105302  16.853508    back  1072170  38711  16174   \n",
      "3     0.795212            5.239447  27.451801    back  1078831  33555  14005   \n",
      "4     0.414621            3.618001  13.089933    back  1111613  22207  11422   \n",
      "...        ...                 ...        ...     ...      ...    ...    ...   \n",
      "1053  1.349114            4.987656  24.876710  follow  1002155  53381  30298   \n",
      "1054  0.767247            3.495845  12.220935  follow  1046373  45812  24532   \n",
      "1055  0.966338            3.527668  12.444442  follow  1016054  54029  31988   \n",
      "1056  0.738081            3.138769   9.851868  follow  1043169  51997  26083   \n",
      "1057  2.213606            5.615943  31.538815  follow   868385  92652  57924   \n",
      "\n",
      "      Bin 8  Bin 9      Sum HOG  ...   SIFT 119   SIFT 120    SIFT 121  \\\n",
      "0      7711   6220  2814.904485  ...   0.000000   0.000000    0.000000   \n",
      "1      4861   4056  1880.101450  ...  53.019558 -91.951920  -35.534462   \n",
      "2      8883   8404  3193.181075  ...  64.790573 -17.979828  -11.774525   \n",
      "3      9516   9568  2813.931181  ...  -8.146722  23.674538   16.879667   \n",
      "4      6288   4955  1720.966500  ...  20.717064 -37.631458  -11.912526   \n",
      "...     ...    ...          ...  ...        ...        ...         ...   \n",
      "1053  18536  17274  5067.250268  ...  27.111052  69.208099  -64.069801   \n",
      "1054  14780  13416  3089.014868  ...  39.517273  42.473213 -129.972305   \n",
      "1055  19087  17610  4046.270988  ...  22.768131 -12.361745  -34.419037   \n",
      "1056  13887  12107  3269.506477  ...  24.446341 -24.754156   44.638222   \n",
      "1057  36021  36304  6394.522295  ... -16.062538 -68.080254  -70.069626   \n",
      "\n",
      "        SIFT 122   SIFT 123    SIFT 124    SIFT 125    SIFT 126    SIFT 127  \\\n",
      "0       0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "1     134.467514 -39.382416   13.225515    5.185749  -25.173859   -2.575677   \n",
      "2      10.488808  39.699814   30.242283  -12.214418  -21.354784   97.238396   \n",
      "3     -29.073320 -32.995296   -8.107094   10.847504 -168.261124 -165.720993   \n",
      "4       2.186476 -57.171062   12.862970  -19.574232   24.376343   33.111610   \n",
      "...          ...        ...         ...         ...         ...         ...   \n",
      "1053    0.011178  18.976994  -21.876720  -63.722820 -223.607834 -112.845856   \n",
      "1054   40.082336  25.547880   -0.518717 -135.653442   -0.696796   57.745838   \n",
      "1055  -54.391846  54.337955 -134.791870   68.316101  -37.639439  -42.464138   \n",
      "1056    7.681120  13.457706   66.544075  -33.429150   -5.936067  -14.595716   \n",
      "1057   31.106388 -21.509348   -3.515615  -34.572914  -14.739547  -23.366438   \n",
      "\n",
      "      Class  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "...     ...  \n",
      "1053      2  \n",
      "1054      2  \n",
      "1055      2  \n",
      "1056      2  \n",
      "1057      2  \n",
      "\n",
      "[1058 rows x 152 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the CSV file with extracted features\n",
    "csv_file_path = './features.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#\n",
    "df = df.drop('Bin 0',axis=1)\n",
    "df = df.drop('Bin 1',axis=1)\n",
    "df = df.drop('Bin 2',axis=1)\n",
    "df = df.drop('Bin 3',axis=1)\n",
    "df = df.drop('Bin 4',axis=1)\n",
    "\n",
    "X = df.drop('Label',axis=1)\n",
    "y = df['Label']\n",
    "# print👍\n",
    "\n",
    "new_col_values = []\n",
    "\n",
    "# loop through rows of DataFrame\n",
    "for row in df.iterrows():\n",
    "    # print(row[1]['Label'])\n",
    "    if row[1]['Label']==\"back\":\n",
    "        new_col_values.append(0)\n",
    "    elif row[1]['Label']==\"down\":\n",
    "        new_col_values.append(1)\n",
    "    elif row[1]['Label']==\"follow\":\n",
    "        new_col_values.append(2)\n",
    "\n",
    "# add new_col to DataFrame\n",
    "df['Class'] = new_col_values\n",
    "\n",
    "df.to_csv(csv_file_path)\n",
    "\n",
    "# print updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4945d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop('Label',axis=1)\n",
    "X = df.iloc[:, :-1]  # selects all rows (:) and all but the last column (:-1) of the DataFrame df.\n",
    "Y = df.iloc[:, -1]    #  selects all rows (:) and the last column (-1) of the DataFrame df.\n",
    "\n",
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.8, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95f5c826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Bin 5</th>\n",
       "      <th>Bin 6</th>\n",
       "      <th>Bin 7</th>\n",
       "      <th>Bin 8</th>\n",
       "      <th>Bin 9</th>\n",
       "      <th>Sum HOG</th>\n",
       "      <th>Mean HOG</th>\n",
       "      <th>...</th>\n",
       "      <th>SIFT 118</th>\n",
       "      <th>SIFT 119</th>\n",
       "      <th>SIFT 120</th>\n",
       "      <th>SIFT 121</th>\n",
       "      <th>SIFT 122</th>\n",
       "      <th>SIFT 123</th>\n",
       "      <th>SIFT 124</th>\n",
       "      <th>SIFT 125</th>\n",
       "      <th>SIFT 126</th>\n",
       "      <th>SIFT 127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.556674</td>\n",
       "      <td>4.696250</td>\n",
       "      <td>22.054761</td>\n",
       "      <td>1094022</td>\n",
       "      <td>31458</td>\n",
       "      <td>15121</td>\n",
       "      <td>7711</td>\n",
       "      <td>6220</td>\n",
       "      <td>2814.904485</td>\n",
       "      <td>0.152868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.359380</td>\n",
       "      <td>3.186641</td>\n",
       "      <td>10.154681</td>\n",
       "      <td>1114348</td>\n",
       "      <td>23904</td>\n",
       "      <td>10572</td>\n",
       "      <td>4861</td>\n",
       "      <td>4056</td>\n",
       "      <td>1880.101450</td>\n",
       "      <td>0.148472</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.772041</td>\n",
       "      <td>53.019558</td>\n",
       "      <td>-91.951920</td>\n",
       "      <td>-35.534462</td>\n",
       "      <td>134.467514</td>\n",
       "      <td>-39.382416</td>\n",
       "      <td>13.225515</td>\n",
       "      <td>5.185749</td>\n",
       "      <td>-25.173859</td>\n",
       "      <td>-2.575677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741009</td>\n",
       "      <td>4.105302</td>\n",
       "      <td>16.853508</td>\n",
       "      <td>1072170</td>\n",
       "      <td>38711</td>\n",
       "      <td>16174</td>\n",
       "      <td>8883</td>\n",
       "      <td>8404</td>\n",
       "      <td>3193.181075</td>\n",
       "      <td>0.146449</td>\n",
       "      <td>...</td>\n",
       "      <td>119.858444</td>\n",
       "      <td>64.790573</td>\n",
       "      <td>-17.979828</td>\n",
       "      <td>-11.774525</td>\n",
       "      <td>10.488808</td>\n",
       "      <td>39.699814</td>\n",
       "      <td>30.242283</td>\n",
       "      <td>-12.214418</td>\n",
       "      <td>-21.354784</td>\n",
       "      <td>97.238396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.795212</td>\n",
       "      <td>5.239447</td>\n",
       "      <td>27.451801</td>\n",
       "      <td>1078831</td>\n",
       "      <td>33555</td>\n",
       "      <td>14005</td>\n",
       "      <td>9516</td>\n",
       "      <td>9568</td>\n",
       "      <td>2813.931181</td>\n",
       "      <td>0.145536</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.751472</td>\n",
       "      <td>-8.146722</td>\n",
       "      <td>23.674538</td>\n",
       "      <td>16.879667</td>\n",
       "      <td>-29.073320</td>\n",
       "      <td>-32.995296</td>\n",
       "      <td>-8.107094</td>\n",
       "      <td>10.847504</td>\n",
       "      <td>-168.261124</td>\n",
       "      <td>-165.720993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.414621</td>\n",
       "      <td>3.618001</td>\n",
       "      <td>13.089933</td>\n",
       "      <td>1111613</td>\n",
       "      <td>22207</td>\n",
       "      <td>11422</td>\n",
       "      <td>6288</td>\n",
       "      <td>4955</td>\n",
       "      <td>1720.966500</td>\n",
       "      <td>0.143342</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.151375</td>\n",
       "      <td>20.717064</td>\n",
       "      <td>-37.631458</td>\n",
       "      <td>-11.912526</td>\n",
       "      <td>2.186476</td>\n",
       "      <td>-57.171062</td>\n",
       "      <td>12.862970</td>\n",
       "      <td>-19.574232</td>\n",
       "      <td>24.376343</td>\n",
       "      <td>33.111610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1.349114</td>\n",
       "      <td>4.987656</td>\n",
       "      <td>24.876710</td>\n",
       "      <td>1002155</td>\n",
       "      <td>53381</td>\n",
       "      <td>30298</td>\n",
       "      <td>18536</td>\n",
       "      <td>17274</td>\n",
       "      <td>5067.250268</td>\n",
       "      <td>0.138893</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.987559</td>\n",
       "      <td>27.111052</td>\n",
       "      <td>69.208099</td>\n",
       "      <td>-64.069801</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>18.976994</td>\n",
       "      <td>-21.876720</td>\n",
       "      <td>-63.722820</td>\n",
       "      <td>-223.607834</td>\n",
       "      <td>-112.845856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>0.767247</td>\n",
       "      <td>3.495845</td>\n",
       "      <td>12.220935</td>\n",
       "      <td>1046373</td>\n",
       "      <td>45812</td>\n",
       "      <td>24532</td>\n",
       "      <td>14780</td>\n",
       "      <td>13416</td>\n",
       "      <td>3089.014868</td>\n",
       "      <td>0.130531</td>\n",
       "      <td>...</td>\n",
       "      <td>8.201757</td>\n",
       "      <td>39.517273</td>\n",
       "      <td>42.473213</td>\n",
       "      <td>-129.972305</td>\n",
       "      <td>40.082336</td>\n",
       "      <td>25.547880</td>\n",
       "      <td>-0.518717</td>\n",
       "      <td>-135.653442</td>\n",
       "      <td>-0.696796</td>\n",
       "      <td>57.745838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>0.966338</td>\n",
       "      <td>3.527668</td>\n",
       "      <td>12.444442</td>\n",
       "      <td>1016054</td>\n",
       "      <td>54029</td>\n",
       "      <td>31988</td>\n",
       "      <td>19087</td>\n",
       "      <td>17610</td>\n",
       "      <td>4046.270988</td>\n",
       "      <td>0.134979</td>\n",
       "      <td>...</td>\n",
       "      <td>-127.677567</td>\n",
       "      <td>22.768131</td>\n",
       "      <td>-12.361745</td>\n",
       "      <td>-34.419037</td>\n",
       "      <td>-54.391846</td>\n",
       "      <td>54.337955</td>\n",
       "      <td>-134.791870</td>\n",
       "      <td>68.316101</td>\n",
       "      <td>-37.639439</td>\n",
       "      <td>-42.464138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>0.738081</td>\n",
       "      <td>3.138769</td>\n",
       "      <td>9.851868</td>\n",
       "      <td>1043169</td>\n",
       "      <td>51997</td>\n",
       "      <td>26083</td>\n",
       "      <td>13887</td>\n",
       "      <td>12107</td>\n",
       "      <td>3269.506477</td>\n",
       "      <td>0.129949</td>\n",
       "      <td>...</td>\n",
       "      <td>67.561134</td>\n",
       "      <td>24.446341</td>\n",
       "      <td>-24.754156</td>\n",
       "      <td>44.638222</td>\n",
       "      <td>7.681120</td>\n",
       "      <td>13.457706</td>\n",
       "      <td>66.544075</td>\n",
       "      <td>-33.429150</td>\n",
       "      <td>-5.936067</td>\n",
       "      <td>-14.595716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>2.213606</td>\n",
       "      <td>5.615943</td>\n",
       "      <td>31.538815</td>\n",
       "      <td>868385</td>\n",
       "      <td>92652</td>\n",
       "      <td>57924</td>\n",
       "      <td>36021</td>\n",
       "      <td>36304</td>\n",
       "      <td>6394.522295</td>\n",
       "      <td>0.128492</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.955219</td>\n",
       "      <td>-16.062538</td>\n",
       "      <td>-68.080254</td>\n",
       "      <td>-70.069626</td>\n",
       "      <td>31.106388</td>\n",
       "      <td>-21.509348</td>\n",
       "      <td>-3.515615</td>\n",
       "      <td>-34.572914</td>\n",
       "      <td>-14.739547</td>\n",
       "      <td>-23.366438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean  Standard Deviation   Variance    Bin 5  Bin 6  Bin 7  Bin 8  \\\n",
       "0     0.556674            4.696250  22.054761  1094022  31458  15121   7711   \n",
       "1     0.359380            3.186641  10.154681  1114348  23904  10572   4861   \n",
       "2     0.741009            4.105302  16.853508  1072170  38711  16174   8883   \n",
       "3     0.795212            5.239447  27.451801  1078831  33555  14005   9516   \n",
       "4     0.414621            3.618001  13.089933  1111613  22207  11422   6288   \n",
       "...        ...                 ...        ...      ...    ...    ...    ...   \n",
       "1053  1.349114            4.987656  24.876710  1002155  53381  30298  18536   \n",
       "1054  0.767247            3.495845  12.220935  1046373  45812  24532  14780   \n",
       "1055  0.966338            3.527668  12.444442  1016054  54029  31988  19087   \n",
       "1056  0.738081            3.138769   9.851868  1043169  51997  26083  13887   \n",
       "1057  2.213606            5.615943  31.538815   868385  92652  57924  36021   \n",
       "\n",
       "      Bin 9      Sum HOG  Mean HOG  ...    SIFT 118   SIFT 119   SIFT 120  \\\n",
       "0      6220  2814.904485  0.152868  ...    0.000000   0.000000   0.000000   \n",
       "1      4056  1880.101450  0.148472  ...  -74.772041  53.019558 -91.951920   \n",
       "2      8404  3193.181075  0.146449  ...  119.858444  64.790573 -17.979828   \n",
       "3      9568  2813.931181  0.145536  ...  -45.751472  -8.146722  23.674538   \n",
       "4      4955  1720.966500  0.143342  ...  -28.151375  20.717064 -37.631458   \n",
       "...     ...          ...       ...  ...         ...        ...        ...   \n",
       "1053  17274  5067.250268  0.138893  ...   -5.987559  27.111052  69.208099   \n",
       "1054  13416  3089.014868  0.130531  ...    8.201757  39.517273  42.473213   \n",
       "1055  17610  4046.270988  0.134979  ... -127.677567  22.768131 -12.361745   \n",
       "1056  12107  3269.506477  0.129949  ...   67.561134  24.446341 -24.754156   \n",
       "1057  36304  6394.522295  0.128492  ...  -41.955219 -16.062538 -68.080254   \n",
       "\n",
       "        SIFT 121    SIFT 122   SIFT 123    SIFT 124    SIFT 125    SIFT 126  \\\n",
       "0       0.000000    0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "1     -35.534462  134.467514 -39.382416   13.225515    5.185749  -25.173859   \n",
       "2     -11.774525   10.488808  39.699814   30.242283  -12.214418  -21.354784   \n",
       "3      16.879667  -29.073320 -32.995296   -8.107094   10.847504 -168.261124   \n",
       "4     -11.912526    2.186476 -57.171062   12.862970  -19.574232   24.376343   \n",
       "...          ...         ...        ...         ...         ...         ...   \n",
       "1053  -64.069801    0.011178  18.976994  -21.876720  -63.722820 -223.607834   \n",
       "1054 -129.972305   40.082336  25.547880   -0.518717 -135.653442   -0.696796   \n",
       "1055  -34.419037  -54.391846  54.337955 -134.791870   68.316101  -37.639439   \n",
       "1056   44.638222    7.681120  13.457706   66.544075  -33.429150   -5.936067   \n",
       "1057  -70.069626   31.106388 -21.509348   -3.515615  -34.572914  -14.739547   \n",
       "\n",
       "        SIFT 127  \n",
       "0       0.000000  \n",
       "1      -2.575677  \n",
       "2      97.238396  \n",
       "3    -165.720993  \n",
       "4      33.111610  \n",
       "...          ...  \n",
       "1053 -112.845856  \n",
       "1054   57.745838  \n",
       "1055  -42.464138  \n",
       "1056  -14.595716  \n",
       "1057  -23.366438  \n",
       "\n",
       "[1058 rows x 150 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e4d5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1053    2\n",
       "1054    2\n",
       "1055    2\n",
       "1056    2\n",
       "1057    2\n",
       "Name: Class, Length: 1058, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d62e740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Bin 5</th>\n",
       "      <th>Bin 6</th>\n",
       "      <th>Bin 7</th>\n",
       "      <th>Bin 8</th>\n",
       "      <th>Bin 9</th>\n",
       "      <th>Sum HOG</th>\n",
       "      <th>Mean HOG</th>\n",
       "      <th>...</th>\n",
       "      <th>SIFT 118</th>\n",
       "      <th>SIFT 119</th>\n",
       "      <th>SIFT 120</th>\n",
       "      <th>SIFT 121</th>\n",
       "      <th>SIFT 122</th>\n",
       "      <th>SIFT 123</th>\n",
       "      <th>SIFT 124</th>\n",
       "      <th>SIFT 125</th>\n",
       "      <th>SIFT 126</th>\n",
       "      <th>SIFT 127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.395749</td>\n",
       "      <td>2.993559</td>\n",
       "      <td>8.961397</td>\n",
       "      <td>692638</td>\n",
       "      <td>4804</td>\n",
       "      <td>3773</td>\n",
       "      <td>3559</td>\n",
       "      <td>3741</td>\n",
       "      <td>718.828264</td>\n",
       "      <td>0.142033</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.364077</td>\n",
       "      <td>17.185566</td>\n",
       "      <td>4.719944</td>\n",
       "      <td>-20.514751</td>\n",
       "      <td>-6.963824</td>\n",
       "      <td>27.971216</td>\n",
       "      <td>-21.066498</td>\n",
       "      <td>21.718739</td>\n",
       "      <td>1.722710</td>\n",
       "      <td>-0.640827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0.565631</td>\n",
       "      <td>6.114240</td>\n",
       "      <td>37.383935</td>\n",
       "      <td>697335</td>\n",
       "      <td>4999</td>\n",
       "      <td>2594</td>\n",
       "      <td>1542</td>\n",
       "      <td>1686</td>\n",
       "      <td>579.192828</td>\n",
       "      <td>0.143471</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.141712</td>\n",
       "      <td>35.656250</td>\n",
       "      <td>-25.227655</td>\n",
       "      <td>-6.477972</td>\n",
       "      <td>8.991025</td>\n",
       "      <td>-188.709259</td>\n",
       "      <td>-4.774416</td>\n",
       "      <td>79.631378</td>\n",
       "      <td>38.242477</td>\n",
       "      <td>21.802788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>1.031885</td>\n",
       "      <td>6.530226</td>\n",
       "      <td>42.643851</td>\n",
       "      <td>677264</td>\n",
       "      <td>7990</td>\n",
       "      <td>5239</td>\n",
       "      <td>3734</td>\n",
       "      <td>3830</td>\n",
       "      <td>1232.412288</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>...</td>\n",
       "      <td>41.050419</td>\n",
       "      <td>-0.057453</td>\n",
       "      <td>50.055229</td>\n",
       "      <td>-63.717213</td>\n",
       "      <td>-14.580037</td>\n",
       "      <td>87.122253</td>\n",
       "      <td>-4.349473</td>\n",
       "      <td>-3.669290</td>\n",
       "      <td>-42.261986</td>\n",
       "      <td>10.519012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0.645607</td>\n",
       "      <td>6.193820</td>\n",
       "      <td>38.363402</td>\n",
       "      <td>696932</td>\n",
       "      <td>5960</td>\n",
       "      <td>2094</td>\n",
       "      <td>1191</td>\n",
       "      <td>2059</td>\n",
       "      <td>496.504969</td>\n",
       "      <td>0.138264</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.855215</td>\n",
       "      <td>36.042580</td>\n",
       "      <td>34.075413</td>\n",
       "      <td>-18.208763</td>\n",
       "      <td>-24.695837</td>\n",
       "      <td>-13.331373</td>\n",
       "      <td>60.803856</td>\n",
       "      <td>-43.332256</td>\n",
       "      <td>30.979496</td>\n",
       "      <td>-24.738859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.149964</td>\n",
       "      <td>1.770950</td>\n",
       "      <td>3.136264</td>\n",
       "      <td>706812</td>\n",
       "      <td>2856</td>\n",
       "      <td>2157</td>\n",
       "      <td>1090</td>\n",
       "      <td>834</td>\n",
       "      <td>440.807715</td>\n",
       "      <td>0.168633</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.605232</td>\n",
       "      <td>-20.277100</td>\n",
       "      <td>-15.782651</td>\n",
       "      <td>13.718862</td>\n",
       "      <td>-11.134361</td>\n",
       "      <td>-0.968225</td>\n",
       "      <td>-13.858082</td>\n",
       "      <td>-135.757111</td>\n",
       "      <td>-42.307270</td>\n",
       "      <td>9.925239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>2.362716</td>\n",
       "      <td>6.395596</td>\n",
       "      <td>40.903648</td>\n",
       "      <td>832399</td>\n",
       "      <td>128542</td>\n",
       "      <td>67458</td>\n",
       "      <td>38195</td>\n",
       "      <td>33420</td>\n",
       "      <td>8949.271374</td>\n",
       "      <td>0.126329</td>\n",
       "      <td>...</td>\n",
       "      <td>83.593719</td>\n",
       "      <td>-68.629028</td>\n",
       "      <td>-52.677101</td>\n",
       "      <td>-28.887522</td>\n",
       "      <td>25.744452</td>\n",
       "      <td>15.880880</td>\n",
       "      <td>-2.844508</td>\n",
       "      <td>-392.439697</td>\n",
       "      <td>-108.001328</td>\n",
       "      <td>-45.398540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.979023</td>\n",
       "      <td>5.981757</td>\n",
       "      <td>35.781414</td>\n",
       "      <td>1086071</td>\n",
       "      <td>29942</td>\n",
       "      <td>11212</td>\n",
       "      <td>5695</td>\n",
       "      <td>5855</td>\n",
       "      <td>2800.138127</td>\n",
       "      <td>0.150618</td>\n",
       "      <td>...</td>\n",
       "      <td>153.133026</td>\n",
       "      <td>45.206825</td>\n",
       "      <td>79.063889</td>\n",
       "      <td>-89.260727</td>\n",
       "      <td>6.035251</td>\n",
       "      <td>-36.186443</td>\n",
       "      <td>-164.663254</td>\n",
       "      <td>-163.252563</td>\n",
       "      <td>53.850796</td>\n",
       "      <td>-97.443893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.666427</td>\n",
       "      <td>3.606549</td>\n",
       "      <td>13.007192</td>\n",
       "      <td>1066480</td>\n",
       "      <td>43049</td>\n",
       "      <td>19533</td>\n",
       "      <td>10962</td>\n",
       "      <td>9229</td>\n",
       "      <td>3251.677323</td>\n",
       "      <td>0.141790</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.079197</td>\n",
       "      <td>-108.933044</td>\n",
       "      <td>-36.067825</td>\n",
       "      <td>-56.453537</td>\n",
       "      <td>1.692349</td>\n",
       "      <td>-110.791862</td>\n",
       "      <td>36.061924</td>\n",
       "      <td>-60.707550</td>\n",
       "      <td>127.437180</td>\n",
       "      <td>242.351257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.382268</td>\n",
       "      <td>4.382471</td>\n",
       "      <td>19.206053</td>\n",
       "      <td>697982</td>\n",
       "      <td>5193</td>\n",
       "      <td>2961</td>\n",
       "      <td>1828</td>\n",
       "      <td>2474</td>\n",
       "      <td>587.808965</td>\n",
       "      <td>0.144923</td>\n",
       "      <td>...</td>\n",
       "      <td>28.080463</td>\n",
       "      <td>-20.961449</td>\n",
       "      <td>-39.358562</td>\n",
       "      <td>51.183037</td>\n",
       "      <td>-43.236012</td>\n",
       "      <td>78.299339</td>\n",
       "      <td>-35.319405</td>\n",
       "      <td>-26.463886</td>\n",
       "      <td>-39.023876</td>\n",
       "      <td>-40.996368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.449139</td>\n",
       "      <td>5.606921</td>\n",
       "      <td>31.437558</td>\n",
       "      <td>699917</td>\n",
       "      <td>4696</td>\n",
       "      <td>2992</td>\n",
       "      <td>1686</td>\n",
       "      <td>1612</td>\n",
       "      <td>448.723627</td>\n",
       "      <td>0.148880</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.961395</td>\n",
       "      <td>-20.160454</td>\n",
       "      <td>37.284252</td>\n",
       "      <td>128.319595</td>\n",
       "      <td>-32.826992</td>\n",
       "      <td>114.237640</td>\n",
       "      <td>-32.790024</td>\n",
       "      <td>1.056358</td>\n",
       "      <td>66.546959</td>\n",
       "      <td>62.340111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>846 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean  Standard Deviation   Variance    Bin 5   Bin 6  Bin 7  Bin 8  \\\n",
       "281   0.395749            2.993559   8.961397   692638    4804   3773   3559   \n",
       "830   0.565631            6.114240  37.383935   697335    4999   2594   1542   \n",
       "683   1.031885            6.530226  42.643851   677264    7990   5239   3734   \n",
       "871   0.645607            6.193820  38.363402   696932    5960   2094   1191   \n",
       "595   0.149964            1.770950   3.136264   706812    2856   2157   1090   \n",
       "...        ...                 ...        ...      ...     ...    ...    ...   \n",
       "1032  2.362716            6.395596  40.903648   832399  128542  67458  38195   \n",
       "73    0.979023            5.981757  35.781414  1086071   29942  11212   5695   \n",
       "998   0.666427            3.606549  13.007192  1066480   43049  19533  10962   \n",
       "206   0.382268            4.382471  19.206053   697982    5193   2961   1828   \n",
       "867   0.449139            5.606921  31.437558   699917    4696   2992   1686   \n",
       "\n",
       "      Bin 9      Sum HOG  Mean HOG  ...    SIFT 118    SIFT 119   SIFT 120  \\\n",
       "281    3741   718.828264  0.142033  ...  -14.364077   17.185566   4.719944   \n",
       "830    1686   579.192828  0.143471  ...  -23.141712   35.656250 -25.227655   \n",
       "683    3830  1232.412288  0.140510  ...   41.050419   -0.057453  50.055229   \n",
       "871    2059   496.504969  0.138264  ...   -2.855215   36.042580  34.075413   \n",
       "595     834   440.807715  0.168633  ...   -5.605232  -20.277100 -15.782651   \n",
       "...     ...          ...       ...  ...         ...         ...        ...   \n",
       "1032  33420  8949.271374  0.126329  ...   83.593719  -68.629028 -52.677101   \n",
       "73     5855  2800.138127  0.150618  ...  153.133026   45.206825  79.063889   \n",
       "998    9229  3251.677323  0.141790  ...  -43.079197 -108.933044 -36.067825   \n",
       "206    2474   587.808965  0.144923  ...   28.080463  -20.961449 -39.358562   \n",
       "867    1612   448.723627  0.148880  ...  -99.961395  -20.160454  37.284252   \n",
       "\n",
       "        SIFT 121   SIFT 122    SIFT 123    SIFT 124    SIFT 125    SIFT 126  \\\n",
       "281   -20.514751  -6.963824   27.971216  -21.066498   21.718739    1.722710   \n",
       "830    -6.477972   8.991025 -188.709259   -4.774416   79.631378   38.242477   \n",
       "683   -63.717213 -14.580037   87.122253   -4.349473   -3.669290  -42.261986   \n",
       "871   -18.208763 -24.695837  -13.331373   60.803856  -43.332256   30.979496   \n",
       "595    13.718862 -11.134361   -0.968225  -13.858082 -135.757111  -42.307270   \n",
       "...          ...        ...         ...         ...         ...         ...   \n",
       "1032  -28.887522  25.744452   15.880880   -2.844508 -392.439697 -108.001328   \n",
       "73    -89.260727   6.035251  -36.186443 -164.663254 -163.252563   53.850796   \n",
       "998   -56.453537   1.692349 -110.791862   36.061924  -60.707550  127.437180   \n",
       "206    51.183037 -43.236012   78.299339  -35.319405  -26.463886  -39.023876   \n",
       "867   128.319595 -32.826992  114.237640  -32.790024    1.056358   66.546959   \n",
       "\n",
       "        SIFT 127  \n",
       "281    -0.640827  \n",
       "830    21.802788  \n",
       "683    10.519012  \n",
       "871   -24.738859  \n",
       "595     9.925239  \n",
       "...          ...  \n",
       "1032  -45.398540  \n",
       "73    -97.443893  \n",
       "998   242.351257  \n",
       "206   -40.996368  \n",
       "867    62.340111  \n",
       "\n",
       "[846 rows x 150 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1824448c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281     0\n",
       "830     1\n",
       "683     1\n",
       "871     1\n",
       "595     0\n",
       "       ..\n",
       "1032    2\n",
       "73      0\n",
       "998     2\n",
       "206     0\n",
       "867     1\n",
       "Name: Class, Length: 846, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f73da86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Bin 5</th>\n",
       "      <th>Bin 6</th>\n",
       "      <th>Bin 7</th>\n",
       "      <th>Bin 8</th>\n",
       "      <th>Bin 9</th>\n",
       "      <th>Sum HOG</th>\n",
       "      <th>Mean HOG</th>\n",
       "      <th>...</th>\n",
       "      <th>SIFT 118</th>\n",
       "      <th>SIFT 119</th>\n",
       "      <th>SIFT 120</th>\n",
       "      <th>SIFT 121</th>\n",
       "      <th>SIFT 122</th>\n",
       "      <th>SIFT 123</th>\n",
       "      <th>SIFT 124</th>\n",
       "      <th>SIFT 125</th>\n",
       "      <th>SIFT 126</th>\n",
       "      <th>SIFT 127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1.051461</td>\n",
       "      <td>8.376339</td>\n",
       "      <td>70.163054</td>\n",
       "      <td>684665</td>\n",
       "      <td>5443</td>\n",
       "      <td>3950</td>\n",
       "      <td>4236</td>\n",
       "      <td>3962</td>\n",
       "      <td>764.386099</td>\n",
       "      <td>0.128167</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.567074</td>\n",
       "      <td>-14.384775</td>\n",
       "      <td>-11.734731</td>\n",
       "      <td>37.541889</td>\n",
       "      <td>13.553376</td>\n",
       "      <td>-0.292490</td>\n",
       "      <td>-14.866241</td>\n",
       "      <td>-24.228504</td>\n",
       "      <td>14.047499</td>\n",
       "      <td>-1.397409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.388549</td>\n",
       "      <td>2.913033</td>\n",
       "      <td>8.485760</td>\n",
       "      <td>693077</td>\n",
       "      <td>4127</td>\n",
       "      <td>3494</td>\n",
       "      <td>3348</td>\n",
       "      <td>4036</td>\n",
       "      <td>622.158726</td>\n",
       "      <td>0.139435</td>\n",
       "      <td>...</td>\n",
       "      <td>6.850658</td>\n",
       "      <td>9.915338</td>\n",
       "      <td>-9.978570</td>\n",
       "      <td>-20.811613</td>\n",
       "      <td>5.730747</td>\n",
       "      <td>-7.889675</td>\n",
       "      <td>-14.599580</td>\n",
       "      <td>-18.032177</td>\n",
       "      <td>16.570675</td>\n",
       "      <td>4.651615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>1.000225</td>\n",
       "      <td>6.148837</td>\n",
       "      <td>37.808200</td>\n",
       "      <td>1097417</td>\n",
       "      <td>15494</td>\n",
       "      <td>7525</td>\n",
       "      <td>5695</td>\n",
       "      <td>7542</td>\n",
       "      <td>1818.978238</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>...</td>\n",
       "      <td>-191.719376</td>\n",
       "      <td>-260.093048</td>\n",
       "      <td>42.887104</td>\n",
       "      <td>-141.701385</td>\n",
       "      <td>-129.961090</td>\n",
       "      <td>-232.116409</td>\n",
       "      <td>232.042786</td>\n",
       "      <td>87.147858</td>\n",
       "      <td>241.042679</td>\n",
       "      <td>176.877167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.280698</td>\n",
       "      <td>2.752521</td>\n",
       "      <td>7.576374</td>\n",
       "      <td>697887</td>\n",
       "      <td>5483</td>\n",
       "      <td>3004</td>\n",
       "      <td>2249</td>\n",
       "      <td>3177</td>\n",
       "      <td>598.177976</td>\n",
       "      <td>0.146720</td>\n",
       "      <td>...</td>\n",
       "      <td>2.614320</td>\n",
       "      <td>-40.131428</td>\n",
       "      <td>-15.332307</td>\n",
       "      <td>0.684482</td>\n",
       "      <td>4.942315</td>\n",
       "      <td>-18.190737</td>\n",
       "      <td>-36.530193</td>\n",
       "      <td>-15.180065</td>\n",
       "      <td>24.401747</td>\n",
       "      <td>4.227867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.522675</td>\n",
       "      <td>3.299020</td>\n",
       "      <td>10.883532</td>\n",
       "      <td>1111035</td>\n",
       "      <td>17915</td>\n",
       "      <td>10108</td>\n",
       "      <td>5928</td>\n",
       "      <td>4734</td>\n",
       "      <td>1678.606597</td>\n",
       "      <td>0.142605</td>\n",
       "      <td>...</td>\n",
       "      <td>-110.610146</td>\n",
       "      <td>-106.468140</td>\n",
       "      <td>-107.971695</td>\n",
       "      <td>98.786995</td>\n",
       "      <td>-55.476513</td>\n",
       "      <td>-142.753998</td>\n",
       "      <td>-32.750801</td>\n",
       "      <td>-76.657181</td>\n",
       "      <td>-32.856384</td>\n",
       "      <td>-189.476608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.445095</td>\n",
       "      <td>3.580498</td>\n",
       "      <td>12.819963</td>\n",
       "      <td>692204</td>\n",
       "      <td>6908</td>\n",
       "      <td>4018</td>\n",
       "      <td>2408</td>\n",
       "      <td>2325</td>\n",
       "      <td>938.480804</td>\n",
       "      <td>0.144515</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.042624</td>\n",
       "      <td>-19.502481</td>\n",
       "      <td>-83.271576</td>\n",
       "      <td>-53.122066</td>\n",
       "      <td>-25.386417</td>\n",
       "      <td>72.956093</td>\n",
       "      <td>-7.632018</td>\n",
       "      <td>24.601561</td>\n",
       "      <td>-14.287844</td>\n",
       "      <td>43.360516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.658623</td>\n",
       "      <td>4.684167</td>\n",
       "      <td>21.941421</td>\n",
       "      <td>691715</td>\n",
       "      <td>3259</td>\n",
       "      <td>2229</td>\n",
       "      <td>1782</td>\n",
       "      <td>2440</td>\n",
       "      <td>726.729216</td>\n",
       "      <td>0.142468</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.182633</td>\n",
       "      <td>-21.588072</td>\n",
       "      <td>-116.423080</td>\n",
       "      <td>4.937935</td>\n",
       "      <td>-1.011641</td>\n",
       "      <td>14.841179</td>\n",
       "      <td>-30.999542</td>\n",
       "      <td>11.898485</td>\n",
       "      <td>-8.679675</td>\n",
       "      <td>3.121428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0.777467</td>\n",
       "      <td>5.432756</td>\n",
       "      <td>29.514836</td>\n",
       "      <td>1103406</td>\n",
       "      <td>19543</td>\n",
       "      <td>8748</td>\n",
       "      <td>5361</td>\n",
       "      <td>6343</td>\n",
       "      <td>1499.245582</td>\n",
       "      <td>0.132829</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.025541</td>\n",
       "      <td>-13.606735</td>\n",
       "      <td>-50.646061</td>\n",
       "      <td>12.016315</td>\n",
       "      <td>-38.295330</td>\n",
       "      <td>-6.618800</td>\n",
       "      <td>13.547494</td>\n",
       "      <td>103.193474</td>\n",
       "      <td>-65.287102</td>\n",
       "      <td>-56.278809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0.411621</td>\n",
       "      <td>4.033740</td>\n",
       "      <td>16.271059</td>\n",
       "      <td>698187</td>\n",
       "      <td>5260</td>\n",
       "      <td>2424</td>\n",
       "      <td>1786</td>\n",
       "      <td>2215</td>\n",
       "      <td>742.820987</td>\n",
       "      <td>0.158994</td>\n",
       "      <td>...</td>\n",
       "      <td>29.394262</td>\n",
       "      <td>-30.534182</td>\n",
       "      <td>-114.291298</td>\n",
       "      <td>-31.632484</td>\n",
       "      <td>-26.607752</td>\n",
       "      <td>-3.680860</td>\n",
       "      <td>-17.245800</td>\n",
       "      <td>-1.621570</td>\n",
       "      <td>0.704188</td>\n",
       "      <td>-29.887348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.208059</td>\n",
       "      <td>2.664033</td>\n",
       "      <td>7.097070</td>\n",
       "      <td>704711</td>\n",
       "      <td>2978</td>\n",
       "      <td>2044</td>\n",
       "      <td>1968</td>\n",
       "      <td>1354</td>\n",
       "      <td>523.684063</td>\n",
       "      <td>0.160639</td>\n",
       "      <td>...</td>\n",
       "      <td>17.660551</td>\n",
       "      <td>3.192819</td>\n",
       "      <td>-97.866966</td>\n",
       "      <td>19.078627</td>\n",
       "      <td>-36.624931</td>\n",
       "      <td>-35.447380</td>\n",
       "      <td>-31.733057</td>\n",
       "      <td>15.593625</td>\n",
       "      <td>31.092730</td>\n",
       "      <td>27.420361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean  Standard Deviation   Variance    Bin 5  Bin 6  Bin 7  Bin 8  \\\n",
       "763  1.051461            8.376339  70.163054   684665   5443   3950   4236   \n",
       "299  0.388549            2.913033   8.485760   693077   4127   3494   3348   \n",
       "897  1.000225            6.148837  37.808200  1097417  15494   7525   5695   \n",
       "341  0.280698            2.752521   7.576374   697887   5483   3004   2249   \n",
       "40   0.522675            3.299020  10.883532  1111035  17915  10108   5928   \n",
       "..        ...                 ...        ...      ...    ...    ...    ...   \n",
       "317  0.445095            3.580498  12.819963   692204   6908   4018   2408   \n",
       "327  0.658623            4.684167  21.941421   691715   3259   2229   1782   \n",
       "644  0.777467            5.432756  29.514836  1103406  19543   8748   5361   \n",
       "608  0.411621            4.033740  16.271059   698187   5260   2424   1786   \n",
       "343  0.208059            2.664033   7.097070   704711   2978   2044   1968   \n",
       "\n",
       "     Bin 9      Sum HOG  Mean HOG  ...    SIFT 118    SIFT 119    SIFT 120  \\\n",
       "763   3962   764.386099  0.128167  ...  -36.567074  -14.384775  -11.734731   \n",
       "299   4036   622.158726  0.139435  ...    6.850658    9.915338   -9.978570   \n",
       "897   7542  1818.978238  0.140625  ... -191.719376 -260.093048   42.887104   \n",
       "341   3177   598.177976  0.146720  ...    2.614320  -40.131428  -15.332307   \n",
       "40    4734  1678.606597  0.142605  ... -110.610146 -106.468140 -107.971695   \n",
       "..     ...          ...       ...  ...         ...         ...         ...   \n",
       "317   2325   938.480804  0.144515  ...  -31.042624  -19.502481  -83.271576   \n",
       "327   2440   726.729216  0.142468  ...   -5.182633  -21.588072 -116.423080   \n",
       "644   6343  1499.245582  0.132829  ...  -20.025541  -13.606735  -50.646061   \n",
       "608   2215   742.820987  0.158994  ...   29.394262  -30.534182 -114.291298   \n",
       "343   1354   523.684063  0.160639  ...   17.660551    3.192819  -97.866966   \n",
       "\n",
       "       SIFT 121    SIFT 122    SIFT 123    SIFT 124    SIFT 125    SIFT 126  \\\n",
       "763   37.541889   13.553376   -0.292490  -14.866241  -24.228504   14.047499   \n",
       "299  -20.811613    5.730747   -7.889675  -14.599580  -18.032177   16.570675   \n",
       "897 -141.701385 -129.961090 -232.116409  232.042786   87.147858  241.042679   \n",
       "341    0.684482    4.942315  -18.190737  -36.530193  -15.180065   24.401747   \n",
       "40    98.786995  -55.476513 -142.753998  -32.750801  -76.657181  -32.856384   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "317  -53.122066  -25.386417   72.956093   -7.632018   24.601561  -14.287844   \n",
       "327    4.937935   -1.011641   14.841179  -30.999542   11.898485   -8.679675   \n",
       "644   12.016315  -38.295330   -6.618800   13.547494  103.193474  -65.287102   \n",
       "608  -31.632484  -26.607752   -3.680860  -17.245800   -1.621570    0.704188   \n",
       "343   19.078627  -36.624931  -35.447380  -31.733057   15.593625   31.092730   \n",
       "\n",
       "       SIFT 127  \n",
       "763   -1.397409  \n",
       "299    4.651615  \n",
       "897  176.877167  \n",
       "341    4.227867  \n",
       "40  -189.476608  \n",
       "..          ...  \n",
       "317   43.360516  \n",
       "327    3.121428  \n",
       "644  -56.278809  \n",
       "608  -29.887348  \n",
       "343   27.420361  \n",
       "\n",
       "[212 rows x 150 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d60bb208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "763    1\n",
       "299    0\n",
       "897    2\n",
       "341    0\n",
       "40     0\n",
       "      ..\n",
       "317    0\n",
       "327    0\n",
       "644    1\n",
       "608    0\n",
       "343    0\n",
       "Name: Class, Length: 212, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d814e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "train_X = sc.fit_transform(x_train)\n",
    "test_X = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bb3b0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.50228912, -0.81817418, -0.76199226, ...,  0.41792913,\n",
       "         0.122379  , -0.02866471],\n",
       "       [-0.26438955,  0.78385119,  0.60212582, ...,  1.19322685,\n",
       "         0.62439166,  0.28777847],\n",
       "       [ 0.38854633,  0.99740058,  0.85457149, ...,  0.07805029,\n",
       "        -0.48224901,  0.12868317],\n",
       "       ...,\n",
       "       [-0.12323499, -0.50349151, -0.56781741, ..., -0.68554179,\n",
       "         1.8504912 ,  3.397396  ],\n",
       "       [-0.52116737, -0.10516575, -0.27030781, ..., -0.22710932,\n",
       "        -0.4377369 , -0.59765663],\n",
       "       [-0.42752241,  0.52341473,  0.316734  , ...,  0.14131427,\n",
       "         1.01347432,  0.85933342]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92fd76c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41596014,  1.94511674,  2.17533471, ..., -0.19718344,\n",
       "         0.29179957, -0.03933211],\n",
       "       [-0.51237198, -0.85951314, -0.78482014, ..., -0.11423094,\n",
       "         0.32648398,  0.04595595],\n",
       "       [ 0.3442099 ,  0.80161179,  0.62248808, ...,  1.29385271,\n",
       "         3.41214954,  2.47424573],\n",
       "       ...,\n",
       "       [ 0.03226382,  0.43400595,  0.22445442, ...,  1.50866125,\n",
       "        -0.79875979, -0.81313101],\n",
       "       [-0.48006229, -0.28418946, -0.4111706 , ...,  0.10546388,\n",
       "         0.10837805, -0.44102528],\n",
       "       [-0.76512721, -0.98733922, -0.85146924, ...,  0.33592999,\n",
       "         0.52610889,  0.36698329]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86a646a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results\n",
      "Decision Tree Accuracy:  77.83018867924528 %\n",
      "Train Accuracy: 0.9361702127659575\n",
      "Test Accuracy: 0.7783018867924528\n",
      "Precision Score:  0.7783018867924528\n",
      "Recall Score:  0.7783018867924528\n",
      "F2 Score:  0.7783018867924528\n",
      "F1 Score:  0.7783018867924528\n",
      "Confusion Matrix: \n",
      "[[109  17   7]\n",
      " [ 11  34   1]\n",
      " [  9   2  22]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Assign model with Decision Tree classifier\n",
    "\n",
    "\n",
    "model_dt = DecisionTreeClassifier(max_depth=6)\n",
    "\n",
    "model_dt.fit(x_train, y_train)\n",
    "\n",
    "joblib.dump(model_dt,\"./decision_tree_model/1.txt\")\n",
    "\n",
    "#predicting the traget variable using testing variables\n",
    "y_pred1 = model_dt.predict(x_test)\n",
    "#Results\n",
    "\n",
    "print(\"Decision Tree Results\")\n",
    "print(\"Decision Tree Accuracy: \",accuracy_score(y_test, y_pred1)*100,\"%\")\n",
    "print(\"Train Accuracy:\",model_dt.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_dt.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred1, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred1, pos_label='positive', average='micro')) # true positive rate, Sensitivity\n",
    "print(\"F2 Score: \",metrics.fbeta_score(y_test, y_pred1, pos_label='positive', average='micro', beta=2.0))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred1, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "129d9662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Best accuracy: 0.7742220675252349\n",
      "Decision Tree Results\n",
      "Decision Tree Accuracy:  80.66037735849056 %\n",
      "Train Accuracy: 0.8475177304964538\n",
      "Test Accuracy: 0.8066037735849056\n",
      "Precision Score:  0.8066037735849056\n",
      "Recall Score:  0.8066037735849056\n",
      "F2 Score:  0.8066037735849056\n",
      "F1 Score:  0.8066037735849056\n",
      "Confusion Matrix: \n",
      "[[119   7   7]\n",
      " [ 13  32   1]\n",
      " [ 12   1  20]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'max_depth': [2, 4, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "# Create a decision tree classifier object\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "#Assign model with Decision Tree classifier\n",
    "model_dt = DecisionTreeClassifier()\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model_dt, param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy score\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best accuracy:\", grid_search.best_score_)\n",
    "\n",
    "\n",
    "joblib.dump(grid_search,\"./decision_tree_tunned_model/1.txt\")\n",
    "\n",
    "#predicting the traget variable using testing variables\n",
    "y_pred1 = grid_search.predict(x_test)\n",
    "#Results\n",
    "print(\"Decision Tree Results\")\n",
    "print(\"Decision Tree Accuracy: \",accuracy_score(y_test, y_pred1)*100,\"%\")\n",
    "print(\"Train Accuracy:\",grid_search.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",grid_search.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred1, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred1, pos_label='positive', average='micro')) # true positive rate, Sensitivity\n",
    "print(\"F2 Score: \",metrics.fbeta_score(y_test, y_pred1, pos_label='positive', average='micro', beta=2.0))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred1, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7daccfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import sklearn.metrics as metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5fba1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest classiffier\n",
    "# df = df.drop('Label',axis=1)\n",
    "X = df.iloc[:, :-1]  # selects all rows (:) and all but the last column (:-1) of the DataFrame df.\n",
    "Y = df.iloc[:, -1]    #  selects all rows (:) and the last column (-1) of the DataFrame df.\n",
    "\n",
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.8, random_state=42)\n",
    "# Train a Random Forest classifier on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0409f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc78be5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Clasifier\n",
      "Random Forest Accuracy:  84.43396226415094 %\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.8443396226415094\n",
      "Precision Score:  0.8123216422719323\n",
      "Recall Score:  0.7949929971988795\n",
      "F1 Score:  0.7958260120014587\n",
      "Confusion Matrix: \n",
      "[[124   3   9]\n",
      " [ 12  33   3]\n",
      " [  6   0  22]]\n"
     ]
    }
   ],
   "source": [
    "model2 = RandomForestClassifier(n_estimators=80, random_state=42)\n",
    "model2.fit(x_train, y_train)\n",
    "joblib.dump(model2,\"./random_forest_model/1.txt\")\n",
    "y_pred2 = model2.predict(x_test)\n",
    "\n",
    "\n",
    "print(\"Random Forest Clasifier\")\n",
    "print(\"Random Forest Accuracy: \",accuracy_score(y_test, y_pred2)*100,\"%\")\n",
    "print(\"Train Accuracy:\",model2.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model2.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred2, average='macro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred2, average='macro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred2, average='macro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "train_cm = confusion_matrix(y_test, y_pred2)\n",
    "print(train_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7762de78",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m# Perform grid search to find the best hyperparameters\u001b[39;00m\n\u001b[0;32m     19\u001b[0m grid_search_rf \u001b[39m=\u001b[39m GridSearchCV(model_rf, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m grid_search_rf\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest hyperparameters: \u001b[39m\u001b[39m\"\u001b[39m, grid_search_rf\u001b[39m.\u001b[39mbest_params_)\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest score: \u001b[39m\u001b[39m\"\u001b[39m, grid_search_rf\u001b[39m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:235\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    233\u001b[0m y_encoded \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(y\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m    234\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_):\n\u001b[1;32m--> 235\u001b[0m     classes_k, y_encoded[:, k] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49munique(y[:, k], return_inverse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mappend(classes_k)\n\u001b[0;32m    237\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_\u001b[39m.\u001b[39mappend(classes_k\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\numpy\\lib\\arraysetops.py:358\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    356\u001b[0m     ret \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (perm[mask],)\n\u001b[0;32m    357\u001b[0m \u001b[39mif\u001b[39;00m return_inverse:\n\u001b[1;32m--> 358\u001b[0m     imask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mcumsum(mask) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    359\u001b[0m     inv_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(mask\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n\u001b[0;32m    360\u001b[0m     inv_idx[perm] \u001b[39m=\u001b[39m imask\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcumsum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2597\u001b[0m, in \u001b[0;36mcumsum\u001b[1;34m(a, axis, dtype, out)\u001b[0m\n\u001b[0;32m   2523\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_cumsum_dispatcher)\n\u001b[0;32m   2524\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcumsum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2525\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2526\u001b[0m \u001b[39m    Return the cumulative sum of the elements along a given axis.\u001b[39;00m\n\u001b[0;32m   2527\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2595\u001b[0m \n\u001b[0;32m   2596\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2597\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mcumsum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype, out\u001b[39m=\u001b[39;49mout)\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Random Forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 4, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "model_rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search_rf = GridSearchCV(model_rf, param_grid, cv=5)\n",
    "grid_search_rf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best hyperparameters: \", grid_search_rf.best_params_)\n",
    "print(\"Best score: \", grid_search_rf.best_score_)\n",
    "\n",
    "joblib.dump(grid_search_rf,\"./cpds/random_forest_tunned_model/1.txt\")\n",
    "\n",
    "y_pred2 = grid_search_rf.predict(x_test)\n",
    "print(\"Random Forest Clasifier\")\n",
    "print(\"Train Accuracy:\",grid_search_rf.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",grid_search_rf.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred2, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred2, pos_label='po  sitive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred2, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c9bef0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Train Accuracy: 0.7659574468085106\n",
      "Test Accuracy: 0.7594339622641509\n",
      "Precision Score:  0.7594339622641509\n",
      "Recall Score:  0.7594339622641509\n",
      "F1 Score:  0.7594339622641509\n",
      "Confusion Matrix: \n",
      "[[118   6  12]\n",
      " [ 18  26   4]\n",
      " [ 11   0  17]]\n"
     ]
    }
   ],
   "source": [
    "#KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_knn = KNeighborsClassifier(n_neighbors = 13)\n",
    "model_knn.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "joblib.dump(model_knn,\"./knn_model/1.txt\")\n",
    "y_pred3 = model_knn.predict(x_test)\n",
    "print(\"KNN\")\n",
    "print(\"Train Accuracy:\",model_knn.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_knn.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49c80c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Best score:  0.7635851026801254\n",
      "KNN\n",
      "Train Accuracy: 0.8274231678486997\n",
      "Test Accuracy: 0.7783018867924528\n",
      "Precision Score:  0.7783018867924528\n",
      "Recall Score:  0.7783018867924528\n",
      "F1 Score:  0.7783018867924528\n",
      "Confusion Matrix: \n",
      "[[120   3  13]\n",
      " [ 19  25   4]\n",
      " [  8   0  20]]\n"
     ]
    }
   ],
   "source": [
    "#KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'n_neighbors': [5, 7, 13, 17, 23],\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'metric': ['euclidean', 'manhattan']}\n",
    "\n",
    "# Create a KNeighborsClassifier object\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search_knn = GridSearchCV(knn, param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "#model_knn.fit(x_train, y_train)\n",
    "grid_search_knn.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and their corresponding score\n",
    "print(\"Best hyperparameters: \", grid_search_knn.best_params_)\n",
    "print(\"Best score: \", grid_search_knn.best_score_)\n",
    "\n",
    "joblib.dump(grid_search_knn,\"./knn_model_tunned/1.txt\")\n",
    "\n",
    "y_pred3 = grid_search_knn.predict(x_test)\n",
    "\n",
    "print(\"KNN\")\n",
    "print(\"Train Accuracy:\",grid_search_knn.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",grid_search_knn.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred3,))\n",
    "# print(\"ROC curve \",metrics.plot_roc_curve(grid_search_knn,x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "350abad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define SVM models with different kernels\n",
    "svc_models = [\n",
    "    SVC(kernel='linear'),\n",
    "    SVC(kernel='poly', degree=2),\n",
    "    SVC(kernel='poly', degree=3),\n",
    "    SVC(kernel='rbf'),\n",
    "    SVC(kernel='sigmoid')\n",
    "]\n",
    "\n",
    "# Train and evaluate SVM models\n",
    "for svc in svc_models:\n",
    "    svc.fit(x_train, y_train)\n",
    "    accuracy = svc.score(x_test, y_test)\n",
    "    print(f\"{svc.kernel} kernel accuracy: {accuracy:.3f}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c9bb7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = [1.340523158, 8.990120269, 80.82226245, 672431, 6754, 4916, 4768, 5535, 912.6672699, 0.134691156, 0.111195749, 0.012364495, 3239, 1887, 1072, 387, 136, 39, 10, 3, 1, 2]\n",
    "# 0.036231864\t0.762807335\t0.581875031\tdown\t0\t0\t0\t0\t0\t712233\t2567\t939\t459\t290\n",
    "my_test_2= [5.335390625, 7.725038413, 59.67621849, 381548, 59452, 45020, 33297, 41230]\n",
    "\n",
    "arr = np.array(my_test)\n",
    "arr = arr.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2fb2a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./cpds/random_forest_model/1.txt']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model2, './cpds/random_forest_model/1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12e8733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_1(optical_flow,frame1,frame2, num_bins=10):\n",
    "    # Calculate the mean, standard deviation, and variance of the optical flow image\n",
    "    \n",
    "\n",
    "    hsv = np.zeros((frame1.shape[0], frame1.shape[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    hsv[...,1] = 255\n",
    "    mag, ang = cv2.cartToPolar(optical_flow[...,0], optical_flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "       \n",
    "    optical_flow_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    of_image = cv2.cvtColor(optical_flow_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    mean = np.mean(of_image)\n",
    "    std = np.std(of_image)\n",
    "    var = np.var(of_image)\n",
    "    # Calculate the histogram of the optical flow image\n",
    "    hist, bins = np.histogram(of_image, bins=num_bins, range=(-10, 10))\n",
    "    hist = hist.tolist()\n",
    "    hist.pop(0)\n",
    "    hist.pop(1)\n",
    "    hist.pop(2)\n",
    "    hist.pop(3)\n",
    "    hist.pop(4)\n",
    "\n",
    "    \n",
    "    h=np.unique(extract_hog_features(of_image))\n",
    "    sum_hog=np.sum(h)\n",
    "    mean_hog=np.mean(h)\n",
    "    std_hog=np.std(h)\n",
    "    var_hog=np.var(h)\n",
    "    hog_hist=np.zeros(10)\n",
    "    for i in h:\n",
    "        if i>0.0 and i<0.1:\n",
    "            hog_hist[0]+=1\n",
    "        elif i>0.1 and i<0.2:\n",
    "            hog_hist[1]+=1\n",
    "        elif i>0.2 and i<0.3:\n",
    "            hog_hist[2]+=1\n",
    "        elif i>0.3 and i<0.4:\n",
    "            hog_hist[3]+=1\n",
    "        elif i>0.4 and i<0.5:\n",
    "            hog_hist[4]+=1\n",
    "        elif i>0.5 and i<0.6:\n",
    "            hog_hist[5]+=1\n",
    "        elif i>0.6 and i<0.7:\n",
    "            hog_hist[6]+=1\n",
    "        elif i>0.7 and i<0.8:\n",
    "            hog_hist[7]+=1\n",
    "        elif i>0.8 and i<0.9:\n",
    "            hog_hist[8]+=1\n",
    "        else:\n",
    "            hog_hist[9]+=1\n",
    "    hog_hist=hog_hist.tolist()\n",
    "    \n",
    "#     print(hist)\n",
    "    \n",
    "\n",
    "\n",
    "    return [mean, std, var] + hist + [sum_hog, mean_hog, std_hog, var_hog] + hog_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35ced23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_2(frame2):\n",
    "    bgSubtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "    fgMask = bgSubtractor.apply(frame2)\n",
    "\n",
    "    # Apply morphological operations to reduce noise and fill gaps\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)\n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(fgMask, None)\n",
    "    # sift_image = cv2.drawKeypoints(gray, keypoints, img)\n",
    "    try:\n",
    "        descriptors=descriptors.T\n",
    "        pca = PCA(n_components=0.95)\n",
    "        # Fit the transformer to the data and transform the data\n",
    "        descriptors = pca.fit_transform(descriptors)\n",
    "        # Reshape the descriptors array into a 1D array\n",
    "        descriptors_1d = descriptors.reshape(-1)\n",
    "        descriptors_1d = descriptors_1d[:128]\n",
    "    except:\n",
    "        descriptors_1d=np.zeros(128)\n",
    "    descriptors_1d=descriptors_1d.tolist()\n",
    "    return descriptors_1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb5cf46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    # define the HOG parameters\n",
    "    orientations = 9\n",
    "    pixels_per_cell = (16, 16)\n",
    "    cells_per_block = (2, 2)\n",
    "    \n",
    "    # compute the HOG features for the image\n",
    "    features = hog(image, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=False, transform_sqrt=True)\n",
    "    print('\\n')\n",
    "    # return the features as a 1D NumPy array\n",
    "    return features.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19468ad8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  2\n",
      "Count Down :  0\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  2\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  5\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  6\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  7\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  8\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  9\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  10\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  11\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  12\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  13\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  14\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  14\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  15\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  16\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  17\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  18\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  19\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  20\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  21\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  22\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  23\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  24\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  25\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  26\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  27\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  28\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  28\n",
      "Count Down :  3\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  28\n",
      "Count Down :  4\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  29\n",
      "Count Down :  4\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  30\n",
      "Count Down :  4\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  31\n",
      "Count Down :  4\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  32\n",
      "Count Down :  4\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  33\n",
      "Count Down :  4\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  34\n",
      "Count Down :  4\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  35\n",
      "Count Down :  4\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  36\n",
      "Count Down :  4\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  37\n",
      "Count Down :  4\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  38\n",
      "Count Down :  4\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  39\n",
      "Count Down :  4\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  39\n",
      "Count Down :  5\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  40\n",
      "Count Down :  5\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  41\n",
      "Count Down :  5\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  41\n",
      "Count Down :  6\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  42\n",
      "Count Down :  6\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  43\n",
      "Count Down :  6\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  44\n",
      "Count Down :  6\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  44\n",
      "Count Down :  7\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  45\n",
      "Count Down :  7\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  46\n",
      "Count Down :  7\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  46\n",
      "Count Down :  8\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  47\n",
      "Count Down :  8\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  48\n",
      "Count Down :  8\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  49\n",
      "Count Down :  8\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  50\n",
      "Count Down :  8\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  51\n",
      "Count Down :  8\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  52\n",
      "Count Down :  8\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  53\n",
      "Count Down :  8\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  54\n",
      "Count Down :  8\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  54\n",
      "Count Down :  9\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  55\n",
      "Count Down :  9\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  55\n",
      "Count Down :  10\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  56\n",
      "Count Down :  10\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  56\n",
      "Count Down :  11\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  56\n",
      "Count Down :  12\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  12\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  13\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  14\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  15\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  16\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  17\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  18\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  19\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  20\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  21\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  22\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  23\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  24\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  25\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  26\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  27\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  28\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  57\n",
      "Count Down :  29\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  58\n",
      "Count Down :  29\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  59\n",
      "Count Down :  29\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  59\n",
      "Count Down :  30\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  60\n",
      "Count Down :  30\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  61\n",
      "Count Down :  30\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  61\n",
      "Count Down :  31\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  62\n",
      "Count Down :  31\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  63\n",
      "Count Down :  31\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  63\n",
      "Count Down :  32\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  63\n",
      "Count Down :  33\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  63\n",
      "Count Down :  34\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  64\n",
      "Count Down :  34\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  65\n",
      "Count Down :  34\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  65\n",
      "Count Down :  35\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  65\n",
      "Count Down :  36\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  66\n",
      "Count Down :  36\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  67\n",
      "Count Down :  36\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  68\n",
      "Count Down :  36\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  68\n",
      "Count Down :  37\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  69\n",
      "Count Down :  37\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  69\n",
      "Count Down :  38\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  70\n",
      "Count Down :  38\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  71\n",
      "Count Down :  38\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  72\n",
      "Count Down :  38\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  73\n",
      "Count Down :  38\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  74\n",
      "Count Down :  38\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  75\n",
      "Count Down :  38\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  75\n",
      "Count Down :  39\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  76\n",
      "Count Down :  39\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  77\n",
      "Count Down :  39\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  78\n",
      "Count Down :  39\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  78\n",
      "Count Down :  40\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  79\n",
      "Count Down :  40\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  80\n",
      "Count Down :  40\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  81\n",
      "Count Down :  40\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  82\n",
      "Count Down :  40\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  83\n",
      "Count Down :  40\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  84\n",
      "Count Down :  40\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  85\n",
      "Count Down :  40\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  86\n",
      "Count Down :  40\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  86\n",
      "Count Down :  40\n",
      "Count Follow :  1\n",
      "\n",
      "\n",
      "Count back :  87\n",
      "Count Down :  40\n",
      "Count Follow :  1\n",
      "\n",
      "\n",
      "Count back :  87\n",
      "Count Down :  40\n",
      "Count Follow :  2\n",
      "\n",
      "\n",
      "Count back :  87\n",
      "Count Down :  40\n",
      "Count Follow :  3\n",
      "\n",
      "\n",
      "Count back :  87\n",
      "Count Down :  40\n",
      "Count Follow :  4\n",
      "\n",
      "\n",
      "Count back :  88\n",
      "Count Down :  40\n",
      "Count Follow :  4\n",
      "\n",
      "\n",
      "Count back :  88\n",
      "Count Down :  40\n",
      "Count Follow :  5\n",
      "\n",
      "\n",
      "Count back :  88\n",
      "Count Down :  40\n",
      "Count Follow :  6\n",
      "\n",
      "\n",
      "Count back :  88\n",
      "Count Down :  40\n",
      "Count Follow :  7\n",
      "\n",
      "\n",
      "Count back :  88\n",
      "Count Down :  40\n",
      "Count Follow :  8\n",
      "\n",
      "\n",
      "Count back :  88\n",
      "Count Down :  40\n",
      "Count Follow :  9\n",
      "\n",
      "\n",
      "Count back :  89\n",
      "Count Down :  40\n",
      "Count Follow :  9\n",
      "\n",
      "\n",
      "Count back :  90\n",
      "Count Down :  40\n",
      "Count Follow :  9\n",
      "\n",
      "\n",
      "Count back :  90\n",
      "Count Down :  40\n",
      "Count Follow :  10\n",
      "\n",
      "\n",
      "Count back :  90\n",
      "Count Down :  40\n",
      "Count Follow :  11\n",
      "\n",
      "\n",
      "Count back :  90\n",
      "Count Down :  40\n",
      "Count Follow :  12\n",
      "\n",
      "\n",
      "Count back :  91\n",
      "Count Down :  40\n",
      "Count Follow :  12\n",
      "\n",
      "\n",
      "Count back :  92\n",
      "Count Down :  40\n",
      "Count Follow :  12\n",
      "\n",
      "\n",
      "Count back :  92\n",
      "Count Down :  40\n",
      "Count Follow :  13\n",
      "\n",
      "\n",
      "Count back :  92\n",
      "Count Down :  40\n",
      "Count Follow :  14\n",
      "\n",
      "\n",
      "Count back :  92\n",
      "Count Down :  41\n",
      "Count Follow :  14\n",
      "\n",
      "\n",
      "Count back :  92\n",
      "Count Down :  41\n",
      "Count Follow :  15\n",
      "\n",
      "\n",
      "Count back :  92\n",
      "Count Down :  41\n",
      "Count Follow :  16\n",
      "\n",
      "\n",
      "Count back :  92\n",
      "Count Down :  42\n",
      "Count Follow :  16\n",
      "\n",
      "\n",
      "Count back :  92\n",
      "Count Down :  42\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  92\n",
      "Count Down :  43\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  92\n",
      "Count Down :  44\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  92\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  93\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  94\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  95\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  96\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  97\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  98\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  99\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  100\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  101\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  102\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  103\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  104\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  105\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  106\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  107\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  108\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  109\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  110\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  111\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  112\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  113\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  114\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  115\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  116\n",
      "Count Down :  45\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  116\n",
      "Count Down :  45\n",
      "Count Follow :  18\n",
      "\n",
      "\n",
      "Count back :  116\n",
      "Count Down :  45\n",
      "Count Follow :  19\n",
      "\n",
      "\n",
      "Count back :  116\n",
      "Count Down :  45\n",
      "Count Follow :  20\n",
      "\n",
      "\n",
      "Count back :  116\n",
      "Count Down :  45\n",
      "Count Follow :  21\n",
      "\n",
      "\n",
      "Count back :  116\n",
      "Count Down :  45\n",
      "Count Follow :  22\n",
      "\n",
      "\n",
      "Count back :  116\n",
      "Count Down :  45\n",
      "Count Follow :  23\n",
      "\n",
      "\n",
      "Count back :  116\n",
      "Count Down :  45\n",
      "Count Follow :  24\n",
      "\n",
      "\n",
      "Count back :  116\n",
      "Count Down :  45\n",
      "Count Follow :  25\n",
      "\n",
      "\n",
      "Count back :  117\n",
      "Count Down :  45\n",
      "Count Follow :  25\n",
      "\n",
      "\n",
      "Count back :  117\n",
      "Count Down :  45\n",
      "Count Follow :  26\n",
      "\n",
      "\n",
      "Count back :  117\n",
      "Count Down :  45\n",
      "Count Follow :  27\n",
      "\n",
      "\n",
      "Count back :  117\n",
      "Count Down :  45\n",
      "Count Follow :  28\n",
      "\n",
      "\n",
      "Count back :  117\n",
      "Count Down :  45\n",
      "Count Follow :  29\n",
      "\n",
      "\n",
      "Count back :  117\n",
      "Count Down :  45\n",
      "Count Follow :  30\n",
      "\n",
      "\n",
      "Count back :  118\n",
      "Count Down :  45\n",
      "Count Follow :  30\n",
      "\n",
      "\n",
      "Count back :  118\n",
      "Count Down :  45\n",
      "Count Follow :  31\n",
      "\n",
      "\n",
      "Count back :  119\n",
      "Count Down :  45\n",
      "Count Follow :  31\n",
      "\n",
      "\n",
      "Count back :  120\n",
      "Count Down :  45\n",
      "Count Follow :  31\n",
      "\n",
      "\n",
      "Count back :  121\n",
      "Count Down :  45\n",
      "Count Follow :  31\n",
      "\n",
      "\n",
      "Count back :  121\n",
      "Count Down :  45\n",
      "Count Follow :  32\n",
      "\n",
      "\n",
      "Count back :  122\n",
      "Count Down :  45\n",
      "Count Follow :  32\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  45\n",
      "Count Follow :  32\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  45\n",
      "Count Follow :  33\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  45\n",
      "Count Follow :  34\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  46\n",
      "Count Follow :  34\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  46\n",
      "Count Follow :  35\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  46\n",
      "Count Follow :  36\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  46\n",
      "Count Follow :  37\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  46\n",
      "Count Follow :  38\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  46\n",
      "Count Follow :  39\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  47\n",
      "Count Follow :  39\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  47\n",
      "Count Follow :  40\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  47\n",
      "Count Follow :  41\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  47\n",
      "Count Follow :  42\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  48\n",
      "Count Follow :  42\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  48\n",
      "Count Follow :  43\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  48\n",
      "Count Follow :  44\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  48\n",
      "Count Follow :  45\n",
      "\n",
      "\n",
      "Count back :  123\n",
      "Count Down :  48\n",
      "Count Follow :  46\n",
      "\n",
      "\n",
      "Count back :  124\n",
      "Count Down :  48\n",
      "Count Follow :  46\n",
      "\n",
      "\n",
      "Count back :  125\n",
      "Count Down :  48\n",
      "Count Follow :  46\n",
      "\n",
      "\n",
      "Count back :  125\n",
      "Count Down :  48\n",
      "Count Follow :  47\n",
      "\n",
      "\n",
      "Count back :  125\n",
      "Count Down :  48\n",
      "Count Follow :  48\n",
      "\n",
      "\n",
      "Count back :  125\n",
      "Count Down :  48\n",
      "Count Follow :  49\n",
      "\n",
      "\n",
      "Count back :  125\n",
      "Count Down :  48\n",
      "Count Follow :  50\n",
      "\n",
      "\n",
      "Count back :  126\n",
      "Count Down :  48\n",
      "Count Follow :  50\n",
      "\n",
      "\n",
      "Count back :  126\n",
      "Count Down :  48\n",
      "Count Follow :  51\n",
      "\n",
      "\n",
      "Count back :  126\n",
      "Count Down :  48\n",
      "Count Follow :  52\n",
      "\n",
      "\n",
      "Count back :  127\n",
      "Count Down :  48\n",
      "Count Follow :  52\n",
      "\n",
      "\n",
      "Count back :  128\n",
      "Count Down :  48\n",
      "Count Follow :  52\n",
      "\n",
      "\n",
      "Count back :  129\n",
      "Count Down :  48\n",
      "Count Follow :  52\n",
      "\n",
      "\n",
      "Count back :  129\n",
      "Count Down :  48\n",
      "Count Follow :  53\n",
      "\n",
      "\n",
      "Count back :  130\n",
      "Count Down :  48\n",
      "Count Follow :  53\n",
      "\n",
      "\n",
      "Count back :  131\n",
      "Count Down :  48\n",
      "Count Follow :  53\n",
      "\n",
      "\n",
      "Count back :  132\n",
      "Count Down :  48\n",
      "Count Follow :  53\n",
      "\n",
      "\n",
      "Count back :  133\n",
      "Count Down :  48\n",
      "Count Follow :  53\n",
      "\n",
      "\n",
      "Count back :  134\n",
      "Count Down :  48\n",
      "Count Follow :  53\n",
      "\n",
      "\n",
      "Count back :  134\n",
      "Count Down :  48\n",
      "Count Follow :  54\n",
      "\n",
      "\n",
      "Count back :  135\n",
      "Count Down :  48\n",
      "Count Follow :  54\n",
      "\n",
      "\n",
      "Count back :  136\n",
      "Count Down :  48\n",
      "Count Follow :  54\n",
      "\n",
      "\n",
      "Count back :  137\n",
      "Count Down :  48\n",
      "Count Follow :  54\n",
      "\n",
      "\n",
      "Count back :  138\n",
      "Count Down :  48\n",
      "Count Follow :  54\n",
      "\n",
      "\n",
      "Count back :  139\n",
      "Count Down :  48\n",
      "Count Follow :  54\n",
      "\n",
      "\n",
      "Count back :  139\n",
      "Count Down :  48\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  140\n",
      "Count Down :  48\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  141\n",
      "Count Down :  48\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  142\n",
      "Count Down :  48\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  143\n",
      "Count Down :  48\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  144\n",
      "Count Down :  48\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  145\n",
      "Count Down :  48\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  146\n",
      "Count Down :  48\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  147\n",
      "Count Down :  48\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  148\n",
      "Count Down :  48\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  149\n",
      "Count Down :  48\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  149\n",
      "Count Down :  49\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  149\n",
      "Count Down :  50\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  150\n",
      "Count Down :  50\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  151\n",
      "Count Down :  50\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  151\n",
      "Count Down :  51\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  152\n",
      "Count Down :  51\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  153\n",
      "Count Down :  51\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  153\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  154\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  155\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  156\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  157\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  158\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  159\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  160\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  161\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  162\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  163\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  164\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  165\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  166\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  167\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  168\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  169\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  170\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  171\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  172\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  173\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  174\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  175\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  176\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  177\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  178\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  179\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  180\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  181\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  182\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  183\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  184\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  185\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  186\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  187\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  188\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  189\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  190\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  191\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  192\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  193\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  194\n",
      "Count Down :  51\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  194\n",
      "Count Down :  52\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  195\n",
      "Count Down :  52\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  196\n",
      "Count Down :  52\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  197\n",
      "Count Down :  52\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  198\n",
      "Count Down :  52\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  199\n",
      "Count Down :  52\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  199\n",
      "Count Down :  53\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  200\n",
      "Count Down :  53\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  201\n",
      "Count Down :  53\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  201\n",
      "Count Down :  54\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  201\n",
      "Count Down :  55\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  202\n",
      "Count Down :  55\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  202\n",
      "Count Down :  56\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  203\n",
      "Count Down :  56\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  204\n",
      "Count Down :  56\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  205\n",
      "Count Down :  56\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  205\n",
      "Count Down :  57\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  205\n",
      "Count Down :  58\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  205\n",
      "Count Down :  59\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  206\n",
      "Count Down :  59\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  207\n",
      "Count Down :  59\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  207\n",
      "Count Down :  60\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  208\n",
      "Count Down :  60\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  208\n",
      "Count Down :  61\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  208\n",
      "Count Down :  62\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  209\n",
      "Count Down :  62\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  210\n",
      "Count Down :  62\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  211\n",
      "Count Down :  62\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  212\n",
      "Count Down :  62\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  212\n",
      "Count Down :  63\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  213\n",
      "Count Down :  63\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  213\n",
      "Count Down :  63\n",
      "Count Follow :  57\n",
      "\n",
      "\n",
      "Count back :  213\n",
      "Count Down :  63\n",
      "Count Follow :  58\n",
      "\n",
      "\n",
      "Count back :  213\n",
      "Count Down :  63\n",
      "Count Follow :  59\n",
      "\n",
      "\n",
      "Count back :  213\n",
      "Count Down :  63\n",
      "Count Follow :  60\n",
      "\n",
      "\n",
      "Count back :  213\n",
      "Count Down :  63\n",
      "Count Follow :  61\n",
      "\n",
      "\n",
      "Count back :  214\n",
      "Count Down :  63\n",
      "Count Follow :  61\n",
      "\n",
      "\n",
      "Count back :  214\n",
      "Count Down :  64\n",
      "Count Follow :  61\n",
      "\n",
      "\n",
      "Count back :  214\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  215\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  216\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  217\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  218\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  219\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  220\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  221\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  222\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  223\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  224\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  225\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  226\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  227\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  228\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  229\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  230\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  231\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  232\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  233\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  234\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  235\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  236\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  237\n",
      "Count Down :  64\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  237\n",
      "Count Down :  64\n",
      "Count Follow :  63\n",
      "\n",
      "\n",
      "Count back :  237\n",
      "Count Down :  64\n",
      "Count Follow :  64\n",
      "\n",
      "\n",
      "Count back :  237\n",
      "Count Down :  64\n",
      "Count Follow :  65\n",
      "\n",
      "\n",
      "Count back :  238\n",
      "Count Down :  64\n",
      "Count Follow :  65\n",
      "\n",
      "\n",
      "Count back :  238\n",
      "Count Down :  65\n",
      "Count Follow :  65\n",
      "\n",
      "\n",
      "Count back :  239\n",
      "Count Down :  65\n",
      "Count Follow :  65\n",
      "\n",
      "\n",
      "Count back :  240\n",
      "Count Down :  65\n",
      "Count Follow :  65\n",
      "\n",
      "\n",
      "Count back :  241\n",
      "Count Down :  65\n",
      "Count Follow :  65\n",
      "\n",
      "\n",
      "Count back :  242\n",
      "Count Down :  65\n",
      "Count Follow :  65\n",
      "\n",
      "\n",
      "Count back :  243\n",
      "Count Down :  65\n",
      "Count Follow :  65\n",
      "\n",
      "\n",
      "Count back :  244\n",
      "Count Down :  65\n",
      "Count Follow :  65\n",
      "\n",
      "\n",
      "Count back :  244\n",
      "Count Down :  65\n",
      "Count Follow :  66\n",
      "\n",
      "\n",
      "Count back :  244\n",
      "Count Down :  65\n",
      "Count Follow :  67\n",
      "\n",
      "\n",
      "Count back :  244\n",
      "Count Down :  65\n",
      "Count Follow :  68\n",
      "\n",
      "\n",
      "Count back :  244\n",
      "Count Down :  65\n",
      "Count Follow :  69\n",
      "\n",
      "\n",
      "Count back :  245\n",
      "Count Down :  65\n",
      "Count Follow :  69\n",
      "\n",
      "\n",
      "Count back :  245\n",
      "Count Down :  65\n",
      "Count Follow :  70\n",
      "\n",
      "\n",
      "Count back :  245\n",
      "Count Down :  65\n",
      "Count Follow :  71\n",
      "\n",
      "\n",
      "Count back :  245\n",
      "Count Down :  65\n",
      "Count Follow :  72\n",
      "\n",
      "\n",
      "Count back :  245\n",
      "Count Down :  65\n",
      "Count Follow :  73\n",
      "\n",
      "\n",
      "Count back :  245\n",
      "Count Down :  65\n",
      "Count Follow :  74\n",
      "\n",
      "\n",
      "Count back :  245\n",
      "Count Down :  65\n",
      "Count Follow :  75\n",
      "\n",
      "\n",
      "Count back :  246\n",
      "Count Down :  65\n",
      "Count Follow :  75\n",
      "\n",
      "\n",
      "Count back :  247\n",
      "Count Down :  65\n",
      "Count Follow :  75\n",
      "\n",
      "\n",
      "Count back :  247\n",
      "Count Down :  65\n",
      "Count Follow :  76\n",
      "\n",
      "\n",
      "Count back :  247\n",
      "Count Down :  65\n",
      "Count Follow :  77\n",
      "\n",
      "\n",
      "Count back :  247\n",
      "Count Down :  65\n",
      "Count Follow :  78\n",
      "\n",
      "\n",
      "Count back :  247\n",
      "Count Down :  65\n",
      "Count Follow :  79\n",
      "\n",
      "\n",
      "Count back :  248\n",
      "Count Down :  65\n",
      "Count Follow :  79\n",
      "\n",
      "\n",
      "Count back :  248\n",
      "Count Down :  65\n",
      "Count Follow :  80\n",
      "\n",
      "\n",
      "Count back :  248\n",
      "Count Down :  65\n",
      "Count Follow :  81\n",
      "\n",
      "\n",
      "Count back :  248\n",
      "Count Down :  65\n",
      "Count Follow :  82\n",
      "\n",
      "\n",
      "Count back :  248\n",
      "Count Down :  65\n",
      "Count Follow :  83\n",
      "\n",
      "\n",
      "Count back :  248\n",
      "Count Down :  65\n",
      "Count Follow :  84\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the saved Random Forest model\n",
    "model = joblib.load('./random_forest_model/1.txt')\n",
    "csv_path_1 = \"./test_video.csv\"\n",
    "# Define the video capture object\n",
    "cap = cv2.VideoCapture('./dataset/001.mp4')\n",
    "with open(csv_path_1, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    ret, frame1 = cap.read()\n",
    "    i = 0\n",
    "    count_back = 0\n",
    "    count_down = 0\n",
    "    count_follow = 0\n",
    "        # Loop through the rest of the frames\n",
    "    while True:\n",
    "\n",
    "            # Read the next frame\n",
    "        ret, frame2 = cap.read()\n",
    "\n",
    "          # If there are no more frames, break out of the loop\n",
    "        if not ret:\n",
    "        \tbreak\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "        # Compute the optical flow using the Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        resArr_1 = extract_features_1(flow,frame1,frame2)\n",
    "        resArr_2 = extract_features_2(frame2)\n",
    "        resArr=resArr_1+resArr_2\n",
    "        frame1=frame2\n",
    "\n",
    "        # Reshape the features into a 2D array\n",
    "        X = np.array(resArr).reshape(1, -1)\n",
    "\n",
    "        # Use the loaded Random Forest model to predict the label\n",
    "        label = model.predict(X)[0]\n",
    "        # print(type(int(label)))\n",
    "        # Display the label on the frame\n",
    "        #cv2.putText(gray1, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        #cv2.imshow('frame', frame1)\n",
    "        if int(label) == 0:\n",
    "            count_back += 1\n",
    "            writer.writerow(\"back\")\n",
    "            # print(\"back\")\n",
    "        elif int(label) == 1:\n",
    "            count_down +=1\n",
    "            writer.writerow(\"down\")\n",
    "            # print(\"down\")\n",
    "        elif int(label) == 2:\n",
    "            count_follow +=1\n",
    "            writer.writerow(\"follow\")\n",
    "            # print(\"follow through\")\n",
    "\n",
    "        print('Count back : ',count_back)\n",
    "        print('Count Down : ',count_down)\n",
    "        print('Count Follow : ',count_follow)\n",
    "\n",
    "#     if count_back > count_down:\n",
    "#         print(\"back\")\n",
    "#     else:\n",
    "#         print(\"down\")\n",
    "\n",
    "    # Check for quit key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# if (count_back>count_down and count_back>count_follow):\n",
    "#     print(\"Video Class: Back\")\n",
    "# if (count_down>count_back and count_down>count_follow):\n",
    "#     print(\"Video Class: Down\")\n",
    "# if (count_follow>count_down and count_back<count_follow):\n",
    "#     print(\"Video Class: Follow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17f05528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  0\n",
      "Count Follow :  1\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  0\n",
      "Count Follow :  2\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  0\n",
      "Count Follow :  3\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  0\n",
      "Count Follow :  4\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  0\n",
      "Count Follow :  5\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  0\n",
      "Count Follow :  6\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  0\n",
      "Count Follow :  7\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  0\n",
      "Count Follow :  8\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  0\n",
      "Count Follow :  9\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  0\n",
      "Count Follow :  10\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  0\n",
      "Count Follow :  11\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  0\n",
      "Count Follow :  12\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  0\n",
      "Count Follow :  13\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  13\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  14\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  15\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  16\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  17\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  18\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  19\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  20\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  21\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  22\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  23\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  24\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  25\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  26\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  27\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  28\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  29\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  30\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  31\n",
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "Count Follow :  32\n",
      "\n",
      "\n",
      "Count back :  2\n",
      "Count Down :  0\n",
      "Count Follow :  32\n",
      "\n",
      "\n",
      "Count back :  2\n",
      "Count Down :  0\n",
      "Count Follow :  33\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  0\n",
      "Count Follow :  33\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  0\n",
      "Count Follow :  34\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  0\n",
      "Count Follow :  35\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  0\n",
      "Count Follow :  36\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  0\n",
      "Count Follow :  37\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  0\n",
      "Count Follow :  38\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  0\n",
      "Count Follow :  39\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  1\n",
      "Count Follow :  39\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  1\n",
      "Count Follow :  40\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  1\n",
      "Count Follow :  41\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  1\n",
      "Count Follow :  42\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  1\n",
      "Count Follow :  43\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  1\n",
      "Count Follow :  44\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  1\n",
      "Count Follow :  45\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  1\n",
      "Count Follow :  46\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  1\n",
      "Count Follow :  47\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  1\n",
      "Count Follow :  48\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  1\n",
      "Count Follow :  49\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  1\n",
      "Count Follow :  50\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  50\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  51\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  52\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  53\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  54\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  55\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  56\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  57\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  58\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  59\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  60\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  61\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  62\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  63\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  64\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  65\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  66\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  67\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  68\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  69\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  70\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  71\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  72\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  73\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  74\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  75\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  76\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  77\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  78\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  79\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  80\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  81\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  82\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  83\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  84\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  85\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  86\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  87\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  88\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  89\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  1\n",
      "Count Follow :  90\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the saved Random Forest model\n",
    "model = joblib.load('./cpds/random_forest_model/1.txt')\n",
    "\n",
    "# Define the video capture object\n",
    "cap = cv2.VideoCapture('./cpds/dataset/follow_022.mp4')\n",
    "ret, frame1 = cap.read()\n",
    "i = 0\n",
    "count_back = 0\n",
    "count_down = 0\n",
    "count_follow = 0\n",
    "    # Loop through the rest of the frames\n",
    "while True:\n",
    "        \n",
    "        # Read the next frame\n",
    "    ret, frame2 = cap.read()\n",
    "        \n",
    "      # If there are no more frames, break out of the loop\n",
    "    if not ret:\n",
    "    \tbreak\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Compute the optical flow using the Farneback method\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    resArr_1 = extract_features_1(flow,frame1,frame2)\n",
    "    resArr_2 = extract_features_2(frame2)\n",
    "    resArr=resArr_1+resArr_2\n",
    "    frame1=frame2\n",
    "    \n",
    "    # Reshape the features into a 2D array\n",
    "    X = np.array(resArr).reshape(1, -1)\n",
    "    \n",
    "    # Use the loaded Random Forest model to predict the label\n",
    "    label = model.predict(X)[0]\n",
    "    # print(type(int(label)))\n",
    "    # Display the label on the frame\n",
    "    #cv2.putText(gray1, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    #cv2.imshow('frame', frame1)\n",
    "    if int(label) == 0:\n",
    "        count_back += 1\n",
    "    elif int(label) == 1:\n",
    "        count_down +=1\n",
    "    elif int(label) == 2:\n",
    "        count_follow +=1\n",
    "        \n",
    "    print('Count back : ',count_back)\n",
    "    print('Count Down : ',count_down)\n",
    "    print('Count Follow : ',count_follow)\n",
    "    \n",
    "#     if count_back > count_down:\n",
    "#         print(\"back\")\n",
    "#     else:\n",
    "#         print(\"down\")\n",
    "\n",
    "    # Check for quit key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(max(count_back, count_down, count_follow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "993a7f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  1\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  2\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  3\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  4\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  5\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  6\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  7\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  8\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  9\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  10\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  11\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  12\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  13\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  14\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  15\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  16\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  17\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  18\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  19\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  20\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  21\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  22\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  23\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  24\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  25\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  26\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  27\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  28\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  29\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  30\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  31\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  32\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  33\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  34\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  35\n",
      "Count Follow :  0\n",
      "\n",
      "\n",
      "Count back :  0\n",
      "Count Down :  36\n",
      "Count Follow :  0\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the saved Random Forest model\n",
    "model = joblib.load('./cpds/random_forest_model/1.txt')\n",
    "\n",
    "# Define the video capture object\n",
    "cap = cv2.VideoCapture('./cpds/dataset/down_001.mp4')\n",
    "ret, frame1 = cap.read()\n",
    "i = 0\n",
    "count_back = 0\n",
    "count_down = 0\n",
    "count_follow = 0\n",
    "    # Loop through the rest of the frames\n",
    "while True:\n",
    "        \n",
    "        # Read the next frame\n",
    "    ret, frame2 = cap.read()\n",
    "        \n",
    "      # If there are no more frames, break out of the loop\n",
    "    if not ret:\n",
    "    \tbreak\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Compute the optical flow using the Farneback method\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    resArr_1 = extract_features_1(flow,frame1,frame2)\n",
    "    resArr_2 = extract_features_2(frame2)\n",
    "    resArr=resArr_1+resArr_2\n",
    "    frame1=frame2\n",
    "    \n",
    "    # Reshape the features into a 2D array\n",
    "    X = np.array(resArr).reshape(1, -1)\n",
    "    \n",
    "    # Use the loaded Random Forest model to predict the label\n",
    "    label = model.predict(X)[0]\n",
    "    # print(type(int(label)))\n",
    "    # Display the label on the frame\n",
    "    #cv2.putText(gray1, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    #cv2.imshow('frame', frame1)\n",
    "    if int(label) == 0:\n",
    "        count_back += 1\n",
    "    elif int(label) == 1:\n",
    "        count_down +=1\n",
    "    elif int(label) == 2:\n",
    "        count_follow +=1\n",
    "        \n",
    "    print('Count back : ',count_back)\n",
    "    print('Count Down : ',count_down)\n",
    "    print('Count Follow : ',count_follow)\n",
    "    \n",
    "#     if count_back > count_down:\n",
    "#         print(\"back\")\n",
    "#     else:\n",
    "#         print(\"down\")\n",
    "\n",
    "    # Check for quit key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(max(count_back, count_down, count_follow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ede6f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0      Mean  Standard Deviation   Variance   Label    Bin 5  \\\n",
      "0              0  0.556674            4.696250  22.054761    back  1094022   \n",
      "1              1  0.359380            3.186641  10.154681    back  1114348   \n",
      "2              2  0.741009            4.105302  16.853508    back  1072170   \n",
      "3              3  0.795212            5.239447  27.451801    back  1078831   \n",
      "4              4  0.414621            3.618001  13.089933    back  1111613   \n",
      "...          ...       ...                 ...        ...     ...      ...   \n",
      "1053        1053  1.349114            4.987656  24.876710  follow  1002155   \n",
      "1054        1054  0.767247            3.495845  12.220935  follow  1046373   \n",
      "1055        1055  0.966338            3.527668  12.444442  follow  1016054   \n",
      "1056        1056  0.738081            3.138769   9.851868  follow  1043169   \n",
      "1057        1057  2.213606            5.615943  31.538815  follow   868385   \n",
      "\n",
      "      Bin 6  Bin 7  Bin 8  Bin 9  ...   SIFT 119   SIFT 120    SIFT 121  \\\n",
      "0     31458  15121   7711   6220  ...   0.000000   0.000000    0.000000   \n",
      "1     23904  10572   4861   4056  ...  53.019558 -91.951920  -35.534462   \n",
      "2     38711  16174   8883   8404  ...  64.790573 -17.979828  -11.774525   \n",
      "3     33555  14005   9516   9568  ...  -8.146722  23.674538   16.879667   \n",
      "4     22207  11422   6288   4955  ...  20.717064 -37.631458  -11.912526   \n",
      "...     ...    ...    ...    ...  ...        ...        ...         ...   \n",
      "1053  53381  30298  18536  17274  ...  27.111052  69.208099  -64.069801   \n",
      "1054  45812  24532  14780  13416  ...  39.517273  42.473213 -129.972305   \n",
      "1055  54029  31988  19087  17610  ...  22.768131 -12.361745  -34.419037   \n",
      "1056  51997  26083  13887  12107  ...  24.446341 -24.754156   44.638222   \n",
      "1057  92652  57924  36021  36304  ... -16.062538 -68.080254  -70.069626   \n",
      "\n",
      "        SIFT 122   SIFT 123    SIFT 124    SIFT 125    SIFT 126    SIFT 127  \\\n",
      "0       0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "1     134.467514 -39.382416   13.225515    5.185749  -25.173859   -2.575677   \n",
      "2      10.488808  39.699814   30.242283  -12.214418  -21.354784   97.238396   \n",
      "3     -29.073320 -32.995296   -8.107094   10.847504 -168.261124 -165.720993   \n",
      "4       2.186476 -57.171062   12.862970  -19.574232   24.376343   33.111610   \n",
      "...          ...        ...         ...         ...         ...         ...   \n",
      "1053    0.011178  18.976994  -21.876720  -63.722820 -223.607834 -112.845856   \n",
      "1054   40.082336  25.547880   -0.518717 -135.653442   -0.696796   57.745838   \n",
      "1055  -54.391846  54.337955 -134.791870   68.316101  -37.639439  -42.464138   \n",
      "1056    7.681120  13.457706   66.544075  -33.429150   -5.936067  -14.595716   \n",
      "1057   31.106388 -21.509348   -3.515615  -34.572914  -14.739547  -23.366438   \n",
      "\n",
      "      Class  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "...     ...  \n",
      "1053      0  \n",
      "1054      0  \n",
      "1055      0  \n",
      "1056      0  \n",
      "1057      0  \n",
      "\n",
      "[1058 rows x 153 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the CSV file with extracted features\n",
    "csv_file_path = './cpds/features.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "X = df.drop('Label',axis=1)\n",
    "y = df['Label']\n",
    "# print👍\n",
    "\n",
    "new_col_values = []\n",
    "\n",
    "# loop through rows of DataFrame\n",
    "for row in df.iterrows():\n",
    "    # print(row[1]['Label'])\n",
    "    if row[1]['Label']==\"down\":\n",
    "        new_col_values.append(1)\n",
    "    else:\n",
    "        new_col_values.append(0)\n",
    "\n",
    "# add new_col to DataFrame\n",
    "df['Class'] = new_col_values\n",
    "\n",
    "df.to_csv(csv_file_path)\n",
    "\n",
    "# print updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d4b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df.drop('Unnamed',axis=1)\n",
    "df = df.drop(df.columns[0],axis=1)\n",
    "df = df.drop('Label',axis=1)\n",
    "X = df.iloc[:, :-1]  # selects all rows (:) and all but the last column (:-1) of the DataFrame df.\n",
    "Y = df.iloc[:, -1]    #  selects all rows (:) and the last column (-1) of the DataFrame df.\n",
    "\n",
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.8, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70741f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Bin 5</th>\n",
       "      <th>Bin 6</th>\n",
       "      <th>Bin 7</th>\n",
       "      <th>Bin 8</th>\n",
       "      <th>Bin 9</th>\n",
       "      <th>Sum HOG</th>\n",
       "      <th>Mean HOG</th>\n",
       "      <th>...</th>\n",
       "      <th>SIFT 118</th>\n",
       "      <th>SIFT 119</th>\n",
       "      <th>SIFT 120</th>\n",
       "      <th>SIFT 121</th>\n",
       "      <th>SIFT 122</th>\n",
       "      <th>SIFT 123</th>\n",
       "      <th>SIFT 124</th>\n",
       "      <th>SIFT 125</th>\n",
       "      <th>SIFT 126</th>\n",
       "      <th>SIFT 127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.556674</td>\n",
       "      <td>4.696250</td>\n",
       "      <td>22.054761</td>\n",
       "      <td>1094022</td>\n",
       "      <td>31458</td>\n",
       "      <td>15121</td>\n",
       "      <td>7711</td>\n",
       "      <td>6220</td>\n",
       "      <td>2814.904485</td>\n",
       "      <td>0.152868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.359380</td>\n",
       "      <td>3.186641</td>\n",
       "      <td>10.154681</td>\n",
       "      <td>1114348</td>\n",
       "      <td>23904</td>\n",
       "      <td>10572</td>\n",
       "      <td>4861</td>\n",
       "      <td>4056</td>\n",
       "      <td>1880.101450</td>\n",
       "      <td>0.148472</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.772041</td>\n",
       "      <td>53.019558</td>\n",
       "      <td>-91.951920</td>\n",
       "      <td>-35.534462</td>\n",
       "      <td>134.467514</td>\n",
       "      <td>-39.382416</td>\n",
       "      <td>13.225515</td>\n",
       "      <td>5.185749</td>\n",
       "      <td>-25.173859</td>\n",
       "      <td>-2.575677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741009</td>\n",
       "      <td>4.105302</td>\n",
       "      <td>16.853508</td>\n",
       "      <td>1072170</td>\n",
       "      <td>38711</td>\n",
       "      <td>16174</td>\n",
       "      <td>8883</td>\n",
       "      <td>8404</td>\n",
       "      <td>3193.181075</td>\n",
       "      <td>0.146449</td>\n",
       "      <td>...</td>\n",
       "      <td>119.858444</td>\n",
       "      <td>64.790573</td>\n",
       "      <td>-17.979828</td>\n",
       "      <td>-11.774525</td>\n",
       "      <td>10.488808</td>\n",
       "      <td>39.699814</td>\n",
       "      <td>30.242283</td>\n",
       "      <td>-12.214418</td>\n",
       "      <td>-21.354784</td>\n",
       "      <td>97.238396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.795212</td>\n",
       "      <td>5.239447</td>\n",
       "      <td>27.451801</td>\n",
       "      <td>1078831</td>\n",
       "      <td>33555</td>\n",
       "      <td>14005</td>\n",
       "      <td>9516</td>\n",
       "      <td>9568</td>\n",
       "      <td>2813.931181</td>\n",
       "      <td>0.145536</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.751472</td>\n",
       "      <td>-8.146722</td>\n",
       "      <td>23.674538</td>\n",
       "      <td>16.879667</td>\n",
       "      <td>-29.073320</td>\n",
       "      <td>-32.995296</td>\n",
       "      <td>-8.107094</td>\n",
       "      <td>10.847504</td>\n",
       "      <td>-168.261124</td>\n",
       "      <td>-165.720993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.414621</td>\n",
       "      <td>3.618001</td>\n",
       "      <td>13.089933</td>\n",
       "      <td>1111613</td>\n",
       "      <td>22207</td>\n",
       "      <td>11422</td>\n",
       "      <td>6288</td>\n",
       "      <td>4955</td>\n",
       "      <td>1720.966500</td>\n",
       "      <td>0.143342</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.151375</td>\n",
       "      <td>20.717064</td>\n",
       "      <td>-37.631458</td>\n",
       "      <td>-11.912526</td>\n",
       "      <td>2.186476</td>\n",
       "      <td>-57.171062</td>\n",
       "      <td>12.862970</td>\n",
       "      <td>-19.574232</td>\n",
       "      <td>24.376343</td>\n",
       "      <td>33.111610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1.349114</td>\n",
       "      <td>4.987656</td>\n",
       "      <td>24.876710</td>\n",
       "      <td>1002155</td>\n",
       "      <td>53381</td>\n",
       "      <td>30298</td>\n",
       "      <td>18536</td>\n",
       "      <td>17274</td>\n",
       "      <td>5067.250268</td>\n",
       "      <td>0.138893</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.987559</td>\n",
       "      <td>27.111052</td>\n",
       "      <td>69.208099</td>\n",
       "      <td>-64.069801</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>18.976994</td>\n",
       "      <td>-21.876720</td>\n",
       "      <td>-63.722820</td>\n",
       "      <td>-223.607834</td>\n",
       "      <td>-112.845856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>0.767247</td>\n",
       "      <td>3.495845</td>\n",
       "      <td>12.220935</td>\n",
       "      <td>1046373</td>\n",
       "      <td>45812</td>\n",
       "      <td>24532</td>\n",
       "      <td>14780</td>\n",
       "      <td>13416</td>\n",
       "      <td>3089.014868</td>\n",
       "      <td>0.130531</td>\n",
       "      <td>...</td>\n",
       "      <td>8.201757</td>\n",
       "      <td>39.517273</td>\n",
       "      <td>42.473213</td>\n",
       "      <td>-129.972305</td>\n",
       "      <td>40.082336</td>\n",
       "      <td>25.547880</td>\n",
       "      <td>-0.518717</td>\n",
       "      <td>-135.653442</td>\n",
       "      <td>-0.696796</td>\n",
       "      <td>57.745838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>0.966338</td>\n",
       "      <td>3.527668</td>\n",
       "      <td>12.444442</td>\n",
       "      <td>1016054</td>\n",
       "      <td>54029</td>\n",
       "      <td>31988</td>\n",
       "      <td>19087</td>\n",
       "      <td>17610</td>\n",
       "      <td>4046.270988</td>\n",
       "      <td>0.134979</td>\n",
       "      <td>...</td>\n",
       "      <td>-127.677567</td>\n",
       "      <td>22.768131</td>\n",
       "      <td>-12.361745</td>\n",
       "      <td>-34.419037</td>\n",
       "      <td>-54.391846</td>\n",
       "      <td>54.337955</td>\n",
       "      <td>-134.791870</td>\n",
       "      <td>68.316101</td>\n",
       "      <td>-37.639439</td>\n",
       "      <td>-42.464138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>0.738081</td>\n",
       "      <td>3.138769</td>\n",
       "      <td>9.851868</td>\n",
       "      <td>1043169</td>\n",
       "      <td>51997</td>\n",
       "      <td>26083</td>\n",
       "      <td>13887</td>\n",
       "      <td>12107</td>\n",
       "      <td>3269.506477</td>\n",
       "      <td>0.129949</td>\n",
       "      <td>...</td>\n",
       "      <td>67.561134</td>\n",
       "      <td>24.446341</td>\n",
       "      <td>-24.754156</td>\n",
       "      <td>44.638222</td>\n",
       "      <td>7.681120</td>\n",
       "      <td>13.457706</td>\n",
       "      <td>66.544075</td>\n",
       "      <td>-33.429150</td>\n",
       "      <td>-5.936067</td>\n",
       "      <td>-14.595716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>2.213606</td>\n",
       "      <td>5.615943</td>\n",
       "      <td>31.538815</td>\n",
       "      <td>868385</td>\n",
       "      <td>92652</td>\n",
       "      <td>57924</td>\n",
       "      <td>36021</td>\n",
       "      <td>36304</td>\n",
       "      <td>6394.522295</td>\n",
       "      <td>0.128492</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.955219</td>\n",
       "      <td>-16.062538</td>\n",
       "      <td>-68.080254</td>\n",
       "      <td>-70.069626</td>\n",
       "      <td>31.106388</td>\n",
       "      <td>-21.509348</td>\n",
       "      <td>-3.515615</td>\n",
       "      <td>-34.572914</td>\n",
       "      <td>-14.739547</td>\n",
       "      <td>-23.366438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean  Standard Deviation   Variance    Bin 5  Bin 6  Bin 7  Bin 8  \\\n",
       "0     0.556674            4.696250  22.054761  1094022  31458  15121   7711   \n",
       "1     0.359380            3.186641  10.154681  1114348  23904  10572   4861   \n",
       "2     0.741009            4.105302  16.853508  1072170  38711  16174   8883   \n",
       "3     0.795212            5.239447  27.451801  1078831  33555  14005   9516   \n",
       "4     0.414621            3.618001  13.089933  1111613  22207  11422   6288   \n",
       "...        ...                 ...        ...      ...    ...    ...    ...   \n",
       "1053  1.349114            4.987656  24.876710  1002155  53381  30298  18536   \n",
       "1054  0.767247            3.495845  12.220935  1046373  45812  24532  14780   \n",
       "1055  0.966338            3.527668  12.444442  1016054  54029  31988  19087   \n",
       "1056  0.738081            3.138769   9.851868  1043169  51997  26083  13887   \n",
       "1057  2.213606            5.615943  31.538815   868385  92652  57924  36021   \n",
       "\n",
       "      Bin 9      Sum HOG  Mean HOG  ...    SIFT 118   SIFT 119   SIFT 120  \\\n",
       "0      6220  2814.904485  0.152868  ...    0.000000   0.000000   0.000000   \n",
       "1      4056  1880.101450  0.148472  ...  -74.772041  53.019558 -91.951920   \n",
       "2      8404  3193.181075  0.146449  ...  119.858444  64.790573 -17.979828   \n",
       "3      9568  2813.931181  0.145536  ...  -45.751472  -8.146722  23.674538   \n",
       "4      4955  1720.966500  0.143342  ...  -28.151375  20.717064 -37.631458   \n",
       "...     ...          ...       ...  ...         ...        ...        ...   \n",
       "1053  17274  5067.250268  0.138893  ...   -5.987559  27.111052  69.208099   \n",
       "1054  13416  3089.014868  0.130531  ...    8.201757  39.517273  42.473213   \n",
       "1055  17610  4046.270988  0.134979  ... -127.677567  22.768131 -12.361745   \n",
       "1056  12107  3269.506477  0.129949  ...   67.561134  24.446341 -24.754156   \n",
       "1057  36304  6394.522295  0.128492  ...  -41.955219 -16.062538 -68.080254   \n",
       "\n",
       "        SIFT 121    SIFT 122   SIFT 123    SIFT 124    SIFT 125    SIFT 126  \\\n",
       "0       0.000000    0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "1     -35.534462  134.467514 -39.382416   13.225515    5.185749  -25.173859   \n",
       "2     -11.774525   10.488808  39.699814   30.242283  -12.214418  -21.354784   \n",
       "3      16.879667  -29.073320 -32.995296   -8.107094   10.847504 -168.261124   \n",
       "4     -11.912526    2.186476 -57.171062   12.862970  -19.574232   24.376343   \n",
       "...          ...         ...        ...         ...         ...         ...   \n",
       "1053  -64.069801    0.011178  18.976994  -21.876720  -63.722820 -223.607834   \n",
       "1054 -129.972305   40.082336  25.547880   -0.518717 -135.653442   -0.696796   \n",
       "1055  -34.419037  -54.391846  54.337955 -134.791870   68.316101  -37.639439   \n",
       "1056   44.638222    7.681120  13.457706   66.544075  -33.429150   -5.936067   \n",
       "1057  -70.069626   31.106388 -21.509348   -3.515615  -34.572914  -14.739547   \n",
       "\n",
       "        SIFT 127  \n",
       "0       0.000000  \n",
       "1      -2.575677  \n",
       "2      97.238396  \n",
       "3    -165.720993  \n",
       "4      33.111610  \n",
       "...          ...  \n",
       "1053 -112.845856  \n",
       "1054   57.745838  \n",
       "1055  -42.464138  \n",
       "1056  -14.595716  \n",
       "1057  -23.366438  \n",
       "\n",
       "[1058 rows x 150 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08dc35a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1053    0\n",
       "1054    0\n",
       "1055    0\n",
       "1056    0\n",
       "1057    0\n",
       "Name: Class, Length: 1058, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f02baa5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Bin 5</th>\n",
       "      <th>Bin 6</th>\n",
       "      <th>Bin 7</th>\n",
       "      <th>Bin 8</th>\n",
       "      <th>Bin 9</th>\n",
       "      <th>Sum HOG</th>\n",
       "      <th>Mean HOG</th>\n",
       "      <th>...</th>\n",
       "      <th>SIFT 118</th>\n",
       "      <th>SIFT 119</th>\n",
       "      <th>SIFT 120</th>\n",
       "      <th>SIFT 121</th>\n",
       "      <th>SIFT 122</th>\n",
       "      <th>SIFT 123</th>\n",
       "      <th>SIFT 124</th>\n",
       "      <th>SIFT 125</th>\n",
       "      <th>SIFT 126</th>\n",
       "      <th>SIFT 127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.395749</td>\n",
       "      <td>2.993559</td>\n",
       "      <td>8.961397</td>\n",
       "      <td>692638</td>\n",
       "      <td>4804</td>\n",
       "      <td>3773</td>\n",
       "      <td>3559</td>\n",
       "      <td>3741</td>\n",
       "      <td>718.828264</td>\n",
       "      <td>0.142033</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.364077</td>\n",
       "      <td>17.185566</td>\n",
       "      <td>4.719944</td>\n",
       "      <td>-20.514751</td>\n",
       "      <td>-6.963824</td>\n",
       "      <td>27.971216</td>\n",
       "      <td>-21.066498</td>\n",
       "      <td>21.718739</td>\n",
       "      <td>1.722710</td>\n",
       "      <td>-0.640827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0.565631</td>\n",
       "      <td>6.114240</td>\n",
       "      <td>37.383935</td>\n",
       "      <td>697335</td>\n",
       "      <td>4999</td>\n",
       "      <td>2594</td>\n",
       "      <td>1542</td>\n",
       "      <td>1686</td>\n",
       "      <td>579.192828</td>\n",
       "      <td>0.143471</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.141712</td>\n",
       "      <td>35.656250</td>\n",
       "      <td>-25.227655</td>\n",
       "      <td>-6.477972</td>\n",
       "      <td>8.991025</td>\n",
       "      <td>-188.709259</td>\n",
       "      <td>-4.774416</td>\n",
       "      <td>79.631378</td>\n",
       "      <td>38.242477</td>\n",
       "      <td>21.802788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>1.031885</td>\n",
       "      <td>6.530226</td>\n",
       "      <td>42.643851</td>\n",
       "      <td>677264</td>\n",
       "      <td>7990</td>\n",
       "      <td>5239</td>\n",
       "      <td>3734</td>\n",
       "      <td>3830</td>\n",
       "      <td>1232.412288</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>...</td>\n",
       "      <td>41.050419</td>\n",
       "      <td>-0.057453</td>\n",
       "      <td>50.055229</td>\n",
       "      <td>-63.717213</td>\n",
       "      <td>-14.580037</td>\n",
       "      <td>87.122253</td>\n",
       "      <td>-4.349473</td>\n",
       "      <td>-3.669290</td>\n",
       "      <td>-42.261986</td>\n",
       "      <td>10.519012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0.645607</td>\n",
       "      <td>6.193820</td>\n",
       "      <td>38.363402</td>\n",
       "      <td>696932</td>\n",
       "      <td>5960</td>\n",
       "      <td>2094</td>\n",
       "      <td>1191</td>\n",
       "      <td>2059</td>\n",
       "      <td>496.504969</td>\n",
       "      <td>0.138264</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.855215</td>\n",
       "      <td>36.042580</td>\n",
       "      <td>34.075413</td>\n",
       "      <td>-18.208763</td>\n",
       "      <td>-24.695837</td>\n",
       "      <td>-13.331373</td>\n",
       "      <td>60.803856</td>\n",
       "      <td>-43.332256</td>\n",
       "      <td>30.979496</td>\n",
       "      <td>-24.738859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.149964</td>\n",
       "      <td>1.770950</td>\n",
       "      <td>3.136264</td>\n",
       "      <td>706812</td>\n",
       "      <td>2856</td>\n",
       "      <td>2157</td>\n",
       "      <td>1090</td>\n",
       "      <td>834</td>\n",
       "      <td>440.807715</td>\n",
       "      <td>0.168633</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.605232</td>\n",
       "      <td>-20.277100</td>\n",
       "      <td>-15.782651</td>\n",
       "      <td>13.718862</td>\n",
       "      <td>-11.134361</td>\n",
       "      <td>-0.968225</td>\n",
       "      <td>-13.858082</td>\n",
       "      <td>-135.757111</td>\n",
       "      <td>-42.307270</td>\n",
       "      <td>9.925239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>2.362716</td>\n",
       "      <td>6.395596</td>\n",
       "      <td>40.903648</td>\n",
       "      <td>832399</td>\n",
       "      <td>128542</td>\n",
       "      <td>67458</td>\n",
       "      <td>38195</td>\n",
       "      <td>33420</td>\n",
       "      <td>8949.271374</td>\n",
       "      <td>0.126329</td>\n",
       "      <td>...</td>\n",
       "      <td>83.593719</td>\n",
       "      <td>-68.629028</td>\n",
       "      <td>-52.677101</td>\n",
       "      <td>-28.887522</td>\n",
       "      <td>25.744452</td>\n",
       "      <td>15.880880</td>\n",
       "      <td>-2.844508</td>\n",
       "      <td>-392.439697</td>\n",
       "      <td>-108.001328</td>\n",
       "      <td>-45.398540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.979023</td>\n",
       "      <td>5.981757</td>\n",
       "      <td>35.781414</td>\n",
       "      <td>1086071</td>\n",
       "      <td>29942</td>\n",
       "      <td>11212</td>\n",
       "      <td>5695</td>\n",
       "      <td>5855</td>\n",
       "      <td>2800.138127</td>\n",
       "      <td>0.150618</td>\n",
       "      <td>...</td>\n",
       "      <td>153.133026</td>\n",
       "      <td>45.206825</td>\n",
       "      <td>79.063889</td>\n",
       "      <td>-89.260727</td>\n",
       "      <td>6.035251</td>\n",
       "      <td>-36.186443</td>\n",
       "      <td>-164.663254</td>\n",
       "      <td>-163.252563</td>\n",
       "      <td>53.850796</td>\n",
       "      <td>-97.443893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.666427</td>\n",
       "      <td>3.606549</td>\n",
       "      <td>13.007192</td>\n",
       "      <td>1066480</td>\n",
       "      <td>43049</td>\n",
       "      <td>19533</td>\n",
       "      <td>10962</td>\n",
       "      <td>9229</td>\n",
       "      <td>3251.677323</td>\n",
       "      <td>0.141790</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.079197</td>\n",
       "      <td>-108.933044</td>\n",
       "      <td>-36.067825</td>\n",
       "      <td>-56.453537</td>\n",
       "      <td>1.692349</td>\n",
       "      <td>-110.791862</td>\n",
       "      <td>36.061924</td>\n",
       "      <td>-60.707550</td>\n",
       "      <td>127.437180</td>\n",
       "      <td>242.351257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.382268</td>\n",
       "      <td>4.382471</td>\n",
       "      <td>19.206053</td>\n",
       "      <td>697982</td>\n",
       "      <td>5193</td>\n",
       "      <td>2961</td>\n",
       "      <td>1828</td>\n",
       "      <td>2474</td>\n",
       "      <td>587.808965</td>\n",
       "      <td>0.144923</td>\n",
       "      <td>...</td>\n",
       "      <td>28.080463</td>\n",
       "      <td>-20.961449</td>\n",
       "      <td>-39.358562</td>\n",
       "      <td>51.183037</td>\n",
       "      <td>-43.236012</td>\n",
       "      <td>78.299339</td>\n",
       "      <td>-35.319405</td>\n",
       "      <td>-26.463886</td>\n",
       "      <td>-39.023876</td>\n",
       "      <td>-40.996368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.449139</td>\n",
       "      <td>5.606921</td>\n",
       "      <td>31.437558</td>\n",
       "      <td>699917</td>\n",
       "      <td>4696</td>\n",
       "      <td>2992</td>\n",
       "      <td>1686</td>\n",
       "      <td>1612</td>\n",
       "      <td>448.723627</td>\n",
       "      <td>0.148880</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.961395</td>\n",
       "      <td>-20.160454</td>\n",
       "      <td>37.284252</td>\n",
       "      <td>128.319595</td>\n",
       "      <td>-32.826992</td>\n",
       "      <td>114.237640</td>\n",
       "      <td>-32.790024</td>\n",
       "      <td>1.056358</td>\n",
       "      <td>66.546959</td>\n",
       "      <td>62.340111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>846 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean  Standard Deviation   Variance    Bin 5   Bin 6  Bin 7  Bin 8  \\\n",
       "281   0.395749            2.993559   8.961397   692638    4804   3773   3559   \n",
       "830   0.565631            6.114240  37.383935   697335    4999   2594   1542   \n",
       "683   1.031885            6.530226  42.643851   677264    7990   5239   3734   \n",
       "871   0.645607            6.193820  38.363402   696932    5960   2094   1191   \n",
       "595   0.149964            1.770950   3.136264   706812    2856   2157   1090   \n",
       "...        ...                 ...        ...      ...     ...    ...    ...   \n",
       "1032  2.362716            6.395596  40.903648   832399  128542  67458  38195   \n",
       "73    0.979023            5.981757  35.781414  1086071   29942  11212   5695   \n",
       "998   0.666427            3.606549  13.007192  1066480   43049  19533  10962   \n",
       "206   0.382268            4.382471  19.206053   697982    5193   2961   1828   \n",
       "867   0.449139            5.606921  31.437558   699917    4696   2992   1686   \n",
       "\n",
       "      Bin 9      Sum HOG  Mean HOG  ...    SIFT 118    SIFT 119   SIFT 120  \\\n",
       "281    3741   718.828264  0.142033  ...  -14.364077   17.185566   4.719944   \n",
       "830    1686   579.192828  0.143471  ...  -23.141712   35.656250 -25.227655   \n",
       "683    3830  1232.412288  0.140510  ...   41.050419   -0.057453  50.055229   \n",
       "871    2059   496.504969  0.138264  ...   -2.855215   36.042580  34.075413   \n",
       "595     834   440.807715  0.168633  ...   -5.605232  -20.277100 -15.782651   \n",
       "...     ...          ...       ...  ...         ...         ...        ...   \n",
       "1032  33420  8949.271374  0.126329  ...   83.593719  -68.629028 -52.677101   \n",
       "73     5855  2800.138127  0.150618  ...  153.133026   45.206825  79.063889   \n",
       "998    9229  3251.677323  0.141790  ...  -43.079197 -108.933044 -36.067825   \n",
       "206    2474   587.808965  0.144923  ...   28.080463  -20.961449 -39.358562   \n",
       "867    1612   448.723627  0.148880  ...  -99.961395  -20.160454  37.284252   \n",
       "\n",
       "        SIFT 121   SIFT 122    SIFT 123    SIFT 124    SIFT 125    SIFT 126  \\\n",
       "281   -20.514751  -6.963824   27.971216  -21.066498   21.718739    1.722710   \n",
       "830    -6.477972   8.991025 -188.709259   -4.774416   79.631378   38.242477   \n",
       "683   -63.717213 -14.580037   87.122253   -4.349473   -3.669290  -42.261986   \n",
       "871   -18.208763 -24.695837  -13.331373   60.803856  -43.332256   30.979496   \n",
       "595    13.718862 -11.134361   -0.968225  -13.858082 -135.757111  -42.307270   \n",
       "...          ...        ...         ...         ...         ...         ...   \n",
       "1032  -28.887522  25.744452   15.880880   -2.844508 -392.439697 -108.001328   \n",
       "73    -89.260727   6.035251  -36.186443 -164.663254 -163.252563   53.850796   \n",
       "998   -56.453537   1.692349 -110.791862   36.061924  -60.707550  127.437180   \n",
       "206    51.183037 -43.236012   78.299339  -35.319405  -26.463886  -39.023876   \n",
       "867   128.319595 -32.826992  114.237640  -32.790024    1.056358   66.546959   \n",
       "\n",
       "        SIFT 127  \n",
       "281    -0.640827  \n",
       "830    21.802788  \n",
       "683    10.519012  \n",
       "871   -24.738859  \n",
       "595     9.925239  \n",
       "...          ...  \n",
       "1032  -45.398540  \n",
       "73    -97.443893  \n",
       "998   242.351257  \n",
       "206   -40.996368  \n",
       "867    62.340111  \n",
       "\n",
       "[846 rows x 150 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "316c1a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281     0\n",
       "830     1\n",
       "683     1\n",
       "871     1\n",
       "595     0\n",
       "       ..\n",
       "1032    0\n",
       "73      0\n",
       "998     0\n",
       "206     0\n",
       "867     1\n",
       "Name: Class, Length: 846, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac078bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Bin 5</th>\n",
       "      <th>Bin 6</th>\n",
       "      <th>Bin 7</th>\n",
       "      <th>Bin 8</th>\n",
       "      <th>Bin 9</th>\n",
       "      <th>Sum HOG</th>\n",
       "      <th>Mean HOG</th>\n",
       "      <th>...</th>\n",
       "      <th>SIFT 118</th>\n",
       "      <th>SIFT 119</th>\n",
       "      <th>SIFT 120</th>\n",
       "      <th>SIFT 121</th>\n",
       "      <th>SIFT 122</th>\n",
       "      <th>SIFT 123</th>\n",
       "      <th>SIFT 124</th>\n",
       "      <th>SIFT 125</th>\n",
       "      <th>SIFT 126</th>\n",
       "      <th>SIFT 127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1.051461</td>\n",
       "      <td>8.376339</td>\n",
       "      <td>70.163054</td>\n",
       "      <td>684665</td>\n",
       "      <td>5443</td>\n",
       "      <td>3950</td>\n",
       "      <td>4236</td>\n",
       "      <td>3962</td>\n",
       "      <td>764.386099</td>\n",
       "      <td>0.128167</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.567074</td>\n",
       "      <td>-14.384775</td>\n",
       "      <td>-11.734731</td>\n",
       "      <td>37.541889</td>\n",
       "      <td>13.553376</td>\n",
       "      <td>-0.292490</td>\n",
       "      <td>-14.866241</td>\n",
       "      <td>-24.228504</td>\n",
       "      <td>14.047499</td>\n",
       "      <td>-1.397409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.388549</td>\n",
       "      <td>2.913033</td>\n",
       "      <td>8.485760</td>\n",
       "      <td>693077</td>\n",
       "      <td>4127</td>\n",
       "      <td>3494</td>\n",
       "      <td>3348</td>\n",
       "      <td>4036</td>\n",
       "      <td>622.158726</td>\n",
       "      <td>0.139435</td>\n",
       "      <td>...</td>\n",
       "      <td>6.850658</td>\n",
       "      <td>9.915338</td>\n",
       "      <td>-9.978570</td>\n",
       "      <td>-20.811613</td>\n",
       "      <td>5.730747</td>\n",
       "      <td>-7.889675</td>\n",
       "      <td>-14.599580</td>\n",
       "      <td>-18.032177</td>\n",
       "      <td>16.570675</td>\n",
       "      <td>4.651615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>1.000225</td>\n",
       "      <td>6.148837</td>\n",
       "      <td>37.808200</td>\n",
       "      <td>1097417</td>\n",
       "      <td>15494</td>\n",
       "      <td>7525</td>\n",
       "      <td>5695</td>\n",
       "      <td>7542</td>\n",
       "      <td>1818.978238</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>...</td>\n",
       "      <td>-191.719376</td>\n",
       "      <td>-260.093048</td>\n",
       "      <td>42.887104</td>\n",
       "      <td>-141.701385</td>\n",
       "      <td>-129.961090</td>\n",
       "      <td>-232.116409</td>\n",
       "      <td>232.042786</td>\n",
       "      <td>87.147858</td>\n",
       "      <td>241.042679</td>\n",
       "      <td>176.877167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.280698</td>\n",
       "      <td>2.752521</td>\n",
       "      <td>7.576374</td>\n",
       "      <td>697887</td>\n",
       "      <td>5483</td>\n",
       "      <td>3004</td>\n",
       "      <td>2249</td>\n",
       "      <td>3177</td>\n",
       "      <td>598.177976</td>\n",
       "      <td>0.146720</td>\n",
       "      <td>...</td>\n",
       "      <td>2.614320</td>\n",
       "      <td>-40.131428</td>\n",
       "      <td>-15.332307</td>\n",
       "      <td>0.684482</td>\n",
       "      <td>4.942315</td>\n",
       "      <td>-18.190737</td>\n",
       "      <td>-36.530193</td>\n",
       "      <td>-15.180065</td>\n",
       "      <td>24.401747</td>\n",
       "      <td>4.227867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.522675</td>\n",
       "      <td>3.299020</td>\n",
       "      <td>10.883532</td>\n",
       "      <td>1111035</td>\n",
       "      <td>17915</td>\n",
       "      <td>10108</td>\n",
       "      <td>5928</td>\n",
       "      <td>4734</td>\n",
       "      <td>1678.606597</td>\n",
       "      <td>0.142605</td>\n",
       "      <td>...</td>\n",
       "      <td>-110.610146</td>\n",
       "      <td>-106.468140</td>\n",
       "      <td>-107.971695</td>\n",
       "      <td>98.786995</td>\n",
       "      <td>-55.476513</td>\n",
       "      <td>-142.753998</td>\n",
       "      <td>-32.750801</td>\n",
       "      <td>-76.657181</td>\n",
       "      <td>-32.856384</td>\n",
       "      <td>-189.476608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.445095</td>\n",
       "      <td>3.580498</td>\n",
       "      <td>12.819963</td>\n",
       "      <td>692204</td>\n",
       "      <td>6908</td>\n",
       "      <td>4018</td>\n",
       "      <td>2408</td>\n",
       "      <td>2325</td>\n",
       "      <td>938.480804</td>\n",
       "      <td>0.144515</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.042624</td>\n",
       "      <td>-19.502481</td>\n",
       "      <td>-83.271576</td>\n",
       "      <td>-53.122066</td>\n",
       "      <td>-25.386417</td>\n",
       "      <td>72.956093</td>\n",
       "      <td>-7.632018</td>\n",
       "      <td>24.601561</td>\n",
       "      <td>-14.287844</td>\n",
       "      <td>43.360516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.658623</td>\n",
       "      <td>4.684167</td>\n",
       "      <td>21.941421</td>\n",
       "      <td>691715</td>\n",
       "      <td>3259</td>\n",
       "      <td>2229</td>\n",
       "      <td>1782</td>\n",
       "      <td>2440</td>\n",
       "      <td>726.729216</td>\n",
       "      <td>0.142468</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.182633</td>\n",
       "      <td>-21.588072</td>\n",
       "      <td>-116.423080</td>\n",
       "      <td>4.937935</td>\n",
       "      <td>-1.011641</td>\n",
       "      <td>14.841179</td>\n",
       "      <td>-30.999542</td>\n",
       "      <td>11.898485</td>\n",
       "      <td>-8.679675</td>\n",
       "      <td>3.121428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0.777467</td>\n",
       "      <td>5.432756</td>\n",
       "      <td>29.514836</td>\n",
       "      <td>1103406</td>\n",
       "      <td>19543</td>\n",
       "      <td>8748</td>\n",
       "      <td>5361</td>\n",
       "      <td>6343</td>\n",
       "      <td>1499.245582</td>\n",
       "      <td>0.132829</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.025541</td>\n",
       "      <td>-13.606735</td>\n",
       "      <td>-50.646061</td>\n",
       "      <td>12.016315</td>\n",
       "      <td>-38.295330</td>\n",
       "      <td>-6.618800</td>\n",
       "      <td>13.547494</td>\n",
       "      <td>103.193474</td>\n",
       "      <td>-65.287102</td>\n",
       "      <td>-56.278809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0.411621</td>\n",
       "      <td>4.033740</td>\n",
       "      <td>16.271059</td>\n",
       "      <td>698187</td>\n",
       "      <td>5260</td>\n",
       "      <td>2424</td>\n",
       "      <td>1786</td>\n",
       "      <td>2215</td>\n",
       "      <td>742.820987</td>\n",
       "      <td>0.158994</td>\n",
       "      <td>...</td>\n",
       "      <td>29.394262</td>\n",
       "      <td>-30.534182</td>\n",
       "      <td>-114.291298</td>\n",
       "      <td>-31.632484</td>\n",
       "      <td>-26.607752</td>\n",
       "      <td>-3.680860</td>\n",
       "      <td>-17.245800</td>\n",
       "      <td>-1.621570</td>\n",
       "      <td>0.704188</td>\n",
       "      <td>-29.887348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.208059</td>\n",
       "      <td>2.664033</td>\n",
       "      <td>7.097070</td>\n",
       "      <td>704711</td>\n",
       "      <td>2978</td>\n",
       "      <td>2044</td>\n",
       "      <td>1968</td>\n",
       "      <td>1354</td>\n",
       "      <td>523.684063</td>\n",
       "      <td>0.160639</td>\n",
       "      <td>...</td>\n",
       "      <td>17.660551</td>\n",
       "      <td>3.192819</td>\n",
       "      <td>-97.866966</td>\n",
       "      <td>19.078627</td>\n",
       "      <td>-36.624931</td>\n",
       "      <td>-35.447380</td>\n",
       "      <td>-31.733057</td>\n",
       "      <td>15.593625</td>\n",
       "      <td>31.092730</td>\n",
       "      <td>27.420361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean  Standard Deviation   Variance    Bin 5  Bin 6  Bin 7  Bin 8  \\\n",
       "763  1.051461            8.376339  70.163054   684665   5443   3950   4236   \n",
       "299  0.388549            2.913033   8.485760   693077   4127   3494   3348   \n",
       "897  1.000225            6.148837  37.808200  1097417  15494   7525   5695   \n",
       "341  0.280698            2.752521   7.576374   697887   5483   3004   2249   \n",
       "40   0.522675            3.299020  10.883532  1111035  17915  10108   5928   \n",
       "..        ...                 ...        ...      ...    ...    ...    ...   \n",
       "317  0.445095            3.580498  12.819963   692204   6908   4018   2408   \n",
       "327  0.658623            4.684167  21.941421   691715   3259   2229   1782   \n",
       "644  0.777467            5.432756  29.514836  1103406  19543   8748   5361   \n",
       "608  0.411621            4.033740  16.271059   698187   5260   2424   1786   \n",
       "343  0.208059            2.664033   7.097070   704711   2978   2044   1968   \n",
       "\n",
       "     Bin 9      Sum HOG  Mean HOG  ...    SIFT 118    SIFT 119    SIFT 120  \\\n",
       "763   3962   764.386099  0.128167  ...  -36.567074  -14.384775  -11.734731   \n",
       "299   4036   622.158726  0.139435  ...    6.850658    9.915338   -9.978570   \n",
       "897   7542  1818.978238  0.140625  ... -191.719376 -260.093048   42.887104   \n",
       "341   3177   598.177976  0.146720  ...    2.614320  -40.131428  -15.332307   \n",
       "40    4734  1678.606597  0.142605  ... -110.610146 -106.468140 -107.971695   \n",
       "..     ...          ...       ...  ...         ...         ...         ...   \n",
       "317   2325   938.480804  0.144515  ...  -31.042624  -19.502481  -83.271576   \n",
       "327   2440   726.729216  0.142468  ...   -5.182633  -21.588072 -116.423080   \n",
       "644   6343  1499.245582  0.132829  ...  -20.025541  -13.606735  -50.646061   \n",
       "608   2215   742.820987  0.158994  ...   29.394262  -30.534182 -114.291298   \n",
       "343   1354   523.684063  0.160639  ...   17.660551    3.192819  -97.866966   \n",
       "\n",
       "       SIFT 121    SIFT 122    SIFT 123    SIFT 124    SIFT 125    SIFT 126  \\\n",
       "763   37.541889   13.553376   -0.292490  -14.866241  -24.228504   14.047499   \n",
       "299  -20.811613    5.730747   -7.889675  -14.599580  -18.032177   16.570675   \n",
       "897 -141.701385 -129.961090 -232.116409  232.042786   87.147858  241.042679   \n",
       "341    0.684482    4.942315  -18.190737  -36.530193  -15.180065   24.401747   \n",
       "40    98.786995  -55.476513 -142.753998  -32.750801  -76.657181  -32.856384   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "317  -53.122066  -25.386417   72.956093   -7.632018   24.601561  -14.287844   \n",
       "327    4.937935   -1.011641   14.841179  -30.999542   11.898485   -8.679675   \n",
       "644   12.016315  -38.295330   -6.618800   13.547494  103.193474  -65.287102   \n",
       "608  -31.632484  -26.607752   -3.680860  -17.245800   -1.621570    0.704188   \n",
       "343   19.078627  -36.624931  -35.447380  -31.733057   15.593625   31.092730   \n",
       "\n",
       "       SIFT 127  \n",
       "763   -1.397409  \n",
       "299    4.651615  \n",
       "897  176.877167  \n",
       "341    4.227867  \n",
       "40  -189.476608  \n",
       "..          ...  \n",
       "317   43.360516  \n",
       "327    3.121428  \n",
       "644  -56.278809  \n",
       "608  -29.887348  \n",
       "343   27.420361  \n",
       "\n",
       "[212 rows x 150 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7204f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "763    1\n",
       "299    0\n",
       "897    0\n",
       "341    0\n",
       "40     0\n",
       "      ..\n",
       "317    0\n",
       "327    0\n",
       "644    1\n",
       "608    0\n",
       "343    0\n",
       "Name: Class, Length: 212, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f010bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "train_X = sc.fit_transform(x_train)\n",
    "test_X = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f39ba587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.50228912, -0.81817418, -0.76199226, ...,  0.41792913,\n",
       "         0.122379  , -0.02866471],\n",
       "       [-0.26438955,  0.78385119,  0.60212582, ...,  1.19322685,\n",
       "         0.62439166,  0.28777847],\n",
       "       [ 0.38854633,  0.99740058,  0.85457149, ...,  0.07805029,\n",
       "        -0.48224901,  0.12868317],\n",
       "       ...,\n",
       "       [-0.12323499, -0.50349151, -0.56781741, ..., -0.68554179,\n",
       "         1.8504912 ,  3.397396  ],\n",
       "       [-0.52116737, -0.10516575, -0.27030781, ..., -0.22710932,\n",
       "        -0.4377369 , -0.59765663],\n",
       "       [-0.42752241,  0.52341473,  0.316734  , ...,  0.14131427,\n",
       "         1.01347432,  0.85933342]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d7f0a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41596014,  1.94511674,  2.17533471, ..., -0.19718344,\n",
       "         0.29179957, -0.03933211],\n",
       "       [-0.51237198, -0.85951314, -0.78482014, ..., -0.11423094,\n",
       "         0.32648398,  0.04595595],\n",
       "       [ 0.3442099 ,  0.80161179,  0.62248808, ...,  1.29385271,\n",
       "         3.41214954,  2.47424573],\n",
       "       ...,\n",
       "       [ 0.03226382,  0.43400595,  0.22445442, ...,  1.50866125,\n",
       "        -0.79875979, -0.81313101],\n",
       "       [-0.48006229, -0.28418946, -0.4111706 , ...,  0.10546388,\n",
       "         0.10837805, -0.44102528],\n",
       "       [-0.76512721, -0.98733922, -0.85146924, ...,  0.33592999,\n",
       "         0.52610889,  0.36698329]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b2fff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results\n",
      "Decision Tree Accuracy:  82.0754716981132 %\n",
      "Train Accuracy: 0.9609929078014184\n",
      "Test Accuracy: 0.8207547169811321\n",
      "Precision Score:  0.8207547169811321\n",
      "Recall Score:  0.8207547169811321\n",
      "F2 Score:  0.8207547169811321\n",
      "F1 Score:  0.8207547169811321\n",
      "Confusion Matrix: \n",
      "[[146  20]\n",
      " [ 18  28]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1396: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "d:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1396: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "d:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1396: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "d:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1396: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Assign model with Decision Tree classifier\n",
    "\n",
    "\n",
    "model_dt = DecisionTreeClassifier(max_depth=6)\n",
    "\n",
    "model_dt.fit(x_train, y_train)\n",
    "\n",
    "joblib.dump(model_dt,\"./cpds/decision_tree_model/1.txt\")\n",
    "\n",
    "#predicting the traget variable using testing variables\n",
    "y_pred1 = model_dt.predict(x_test)\n",
    "#Results\n",
    "\n",
    "print(\"Decision Tree Results\")\n",
    "print(\"Decision Tree Accuracy: \",accuracy_score(y_test, y_pred1)*100,\"%\")\n",
    "print(\"Train Accuracy:\",model_dt.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_dt.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred1, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred1, pos_label='positive', average='micro')) # true positive rate, Sensitivity\n",
    "print(\"F2 Score: \",metrics.fbeta_score(y_test, y_pred1, pos_label='positive', average='micro', beta=2.0))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred1, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efb7baff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'random'}\n",
      "Best accuracy: 0.8699547511312217\n",
      "Decision Tree Results\n",
      "Decision Tree Accuracy:  82.0754716981132 %\n",
      "Train Accuracy: 0.8404255319148937\n",
      "Test Accuracy: 0.8207547169811321\n",
      "Precision Score:  0.8207547169811321\n",
      "Recall Score:  0.8207547169811321\n",
      "F2 Score:  0.8207547169811321\n",
      "F1 Score:  0.8207547169811321\n",
      "Confusion Matrix: \n",
      "[[140  26]\n",
      " [ 12  34]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1396: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "d:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1396: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "d:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1396: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "d:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1396: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'max_depth': [2, 4, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "# Create a decision tree classifier object\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "#Assign model with Decision Tree classifier\n",
    "model_dt = DecisionTreeClassifier()\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model_dt, param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy score\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best accuracy:\", grid_search.best_score_)\n",
    "\n",
    "\n",
    "joblib.dump(grid_search,\"./cpds/decision_tree_tunned_model/1.txt\")\n",
    "\n",
    "#predicting the traget variable using testing variables\n",
    "y_pred1 = grid_search.predict(x_test)\n",
    "#Results\n",
    "print(\"Decision Tree Results\")\n",
    "print(\"Decision Tree Accuracy: \",accuracy_score(y_test, y_pred1)*100,\"%\")\n",
    "print(\"Train Accuracy:\",grid_search.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",grid_search.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred1, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred1, pos_label='positive', average='micro')) # true positive rate, Sensitivity\n",
    "print(\"F2 Score: \",metrics.fbeta_score(y_test, y_pred1, pos_label='positive', average='micro', beta=2.0))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred1, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77fe2393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import sklearn.metrics as metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84269780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest classiffier\n",
    "# df = df.drop('Label',axis=1)\n",
    "X = df.iloc[:, :-1]  # selects all rows (:) and all but the last column (:-1) of the DataFrame df.\n",
    "Y = df.iloc[:, -1]    #  selects all rows (:) and the last column (-1) of the DataFrame df.\n",
    "\n",
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.8, random_state=42)\n",
    "# Train a Random Forest classifier on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f63a5d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a0d871f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Clasifier\n",
      "Random Forest Accuracy:  90.56603773584906 %\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9056603773584906\n",
      "Precision Score:  0.898989898989899\n",
      "Recall Score:  0.8211382113821137\n",
      "F1 Score:  0.8515406162464986\n",
      "Confusion Matrix: \n",
      "[[160   4]\n",
      " [ 16  32]]\n"
     ]
    }
   ],
   "source": [
    "model2 = RandomForestClassifier(n_estimators=80, random_state=42)\n",
    "model2.fit(x_train, y_train)\n",
    "joblib.dump(model2,\"./cpds/random_forest_model/1.txt\")\n",
    "y_pred2 = model2.predict(x_test)\n",
    "\n",
    "\n",
    "print(\"Random Forest Clasifier\")\n",
    "print(\"Random Forest Accuracy: \",accuracy_score(y_test, y_pred2)*100,\"%\")\n",
    "print(\"Train Accuracy:\",model2.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model2.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred2, average='macro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred2, average='macro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred2, average='macro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "train_cm = confusion_matrix(y_test, y_pred2)\n",
    "print(train_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "053d82f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best score:  0.9574382178907065\n",
      "Random Forest Clasifier\n",
      "Train Accuracy: 0.9929078014184397\n",
      "Test Accuracy: 0.9528301886792453\n",
      "Precision Score:  0.9528301886792453\n",
      "Recall Score:  0.9528301886792453\n",
      "F1 Score:  0.9528301886792453\n",
      "Confusion Matrix: \n",
      "[[163   1]\n",
      " [  9  39]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 4, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "model_rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search_rf = GridSearchCV(model_rf, param_grid, cv=5)\n",
    "grid_search_rf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best hyperparameters: \", grid_search_rf.best_params_)\n",
    "print(\"Best score: \", grid_search_rf.best_score_)\n",
    "\n",
    "joblib.dump(grid_search_rf,\"./cpds/random_forest_tunned_model/1.txt\")\n",
    "\n",
    "y_pred2 = grid_search_rf.predict(x_test)\n",
    "print(\"Random Forest Clasifier\")\n",
    "print(\"Train Accuracy:\",grid_search_rf.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",grid_search_rf.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred2, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred2, pos_label='po  sitive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred2, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8af397cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Train Accuracy: 0.8581560283687943\n",
      "Test Accuracy: 0.8632075471698113\n",
      "Precision Score:  0.8632075471698113\n",
      "Recall Score:  0.8632075471698113\n",
      "F1 Score:  0.8632075471698113\n",
      "Confusion Matrix: \n",
      "[[158   6]\n",
      " [ 23  25]]\n"
     ]
    }
   ],
   "source": [
    "#KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_knn = KNeighborsClassifier(n_neighbors = 13)\n",
    "model_knn.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "joblib.dump(model_knn,\"./cpds/knn_model/1.txt\")\n",
    "y_pred3 = model_knn.predict(x_test)\n",
    "print(\"KNN\")\n",
    "print(\"Train Accuracy:\",model_knn.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_knn.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f3044ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Best score:  0.8510755308040375\n",
      "KNN\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.8773584905660378\n",
      "Precision Score:  0.8773584905660378\n",
      "Recall Score:  0.8773584905660378\n",
      "F1 Score:  0.8773584905660378\n",
      "Confusion Matrix: \n",
      "[[161   3]\n",
      " [ 23  25]]\n"
     ]
    }
   ],
   "source": [
    "#KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'n_neighbors': [5, 7, 13, 17, 23],\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'metric': ['euclidean', 'manhattan']}\n",
    "\n",
    "# Create a KNeighborsClassifier object\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search_knn = GridSearchCV(knn, param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "#model_knn.fit(x_train, y_train)\n",
    "grid_search_knn.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and their corresponding score\n",
    "print(\"Best hyperparameters: \", grid_search_knn.best_params_)\n",
    "print(\"Best score: \", grid_search_knn.best_score_)\n",
    "\n",
    "joblib.dump(grid_search_knn,\"./cpds/knn_model_tunned/1.txt\")\n",
    "\n",
    "y_pred3 = grid_search_knn.predict(x_test)\n",
    "\n",
    "print(\"KNN\")\n",
    "print(\"Train Accuracy:\",grid_search_knn.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",grid_search_knn.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred3,))\n",
    "# print(\"ROC curve \",metrics.plot_roc_curve(grid_search_knn,x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85343887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear kernel accuracy: 0.830\n",
      "poly kernel accuracy: 0.774\n",
      "poly kernel accuracy: 0.774\n",
      "rbf kernel accuracy: 0.774\n",
      "sigmoid kernel accuracy: 0.774\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define SVM models with different kernels\n",
    "svc_models = [\n",
    "    SVC(kernel='linear'),\n",
    "    SVC(kernel='poly', degree=2),\n",
    "    SVC(kernel='poly', degree=3),\n",
    "    SVC(kernel='rbf'),\n",
    "    SVC(kernel='sigmoid')\n",
    "]\n",
    "\n",
    "# Train and evaluate SVM models\n",
    "for svc in svc_models:\n",
    "    svc.fit(x_train, y_train)\n",
    "    accuracy = svc.score(x_test, y_test)\n",
    "    print(f\"{svc.kernel} kernel accuracy: {accuracy:.3f}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "243ff342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./cpds/random_forest_model/1.txt']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model2, './cpds/random_forest_model/1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "349eb13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_1(optical_flow,frame1,frame2, num_bins=10):\n",
    "    # Calculate the mean, standard deviation, and variance of the optical flow image\n",
    "    \n",
    "\n",
    "    hsv = np.zeros((frame1.shape[0], frame1.shape[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    hsv[...,1] = 255\n",
    "    mag, ang = cv2.cartToPolar(optical_flow[...,0], optical_flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "       \n",
    "    optical_flow_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    of_image = cv2.cvtColor(optical_flow_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    mean = np.mean(of_image)\n",
    "    std = np.std(of_image)\n",
    "    var = np.var(of_image)\n",
    "    # Calculate the histogram of the optical flow image\n",
    "    hist, bins = np.histogram(of_image, bins=num_bins, range=(-10, 10))\n",
    "    hist = hist.tolist()\n",
    "    hist.pop(0)\n",
    "    hist.pop(1)\n",
    "    hist.pop(2)\n",
    "    hist.pop(3)\n",
    "    hist.pop(4)\n",
    "\n",
    "    \n",
    "    h=np.unique(extract_hog_features(of_image))\n",
    "    sum_hog=np.sum(h)\n",
    "    mean_hog=np.mean(h)\n",
    "    std_hog=np.std(h)\n",
    "    var_hog=np.var(h)\n",
    "    hog_hist=np.zeros(10)\n",
    "    for i in h:\n",
    "        if i>0.0 and i<0.1:\n",
    "            hog_hist[0]+=1\n",
    "        elif i>0.1 and i<0.2:\n",
    "            hog_hist[1]+=1\n",
    "        elif i>0.2 and i<0.3:\n",
    "            hog_hist[2]+=1\n",
    "        elif i>0.3 and i<0.4:\n",
    "            hog_hist[3]+=1\n",
    "        elif i>0.4 and i<0.5:\n",
    "            hog_hist[4]+=1\n",
    "        elif i>0.5 and i<0.6:\n",
    "            hog_hist[5]+=1\n",
    "        elif i>0.6 and i<0.7:\n",
    "            hog_hist[6]+=1\n",
    "        elif i>0.7 and i<0.8:\n",
    "            hog_hist[7]+=1\n",
    "        elif i>0.8 and i<0.9:\n",
    "            hog_hist[8]+=1\n",
    "        else:\n",
    "            hog_hist[9]+=1\n",
    "    hog_hist=hog_hist.tolist()\n",
    "    \n",
    "#     print(hist)\n",
    "    \n",
    "\n",
    "\n",
    "    return [mean, std, var] + hist + [sum_hog, mean_hog, std_hog, var_hog] + hog_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "939660e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_2(frame2):\n",
    "    bgSubtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "    fgMask = bgSubtractor.apply(frame2)\n",
    "\n",
    "    # Apply morphological operations to reduce noise and fill gaps\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)\n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(fgMask, None)\n",
    "    # sift_image = cv2.drawKeypoints(gray, keypoints, img)\n",
    "    try:\n",
    "        descriptors=descriptors.T\n",
    "        pca = PCA(n_components=0.95)\n",
    "        # Fit the transformer to the data and transform the data\n",
    "        descriptors = pca.fit_transform(descriptors)\n",
    "        # Reshape the descriptors array into a 1D array\n",
    "        descriptors_1d = descriptors.reshape(-1)\n",
    "        descriptors_1d = descriptors_1d[:128]\n",
    "    except:\n",
    "        descriptors_1d=np.zeros(128)\n",
    "    descriptors_1d=descriptors_1d.tolist()\n",
    "    return descriptors_1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b7e57fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  1\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  2\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  3\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  4\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  5\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  6\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  7\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  8\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  9\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  10\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  11\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  12\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  13\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  14\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  15\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  16\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  17\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  18\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  19\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  20\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  21\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  22\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  23\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  24\n",
      "\n",
      "\n",
      "Count Down :  0\n",
      "Count other :  25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39m# Compute the optical flow using the Farneback method\u001b[39;00m\n\u001b[0;32m     28\u001b[0m flow \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcalcOpticalFlowFarneback(gray1, gray2, \u001b[39mNone\u001b[39;00m, \u001b[39m0.5\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m15\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m1.2\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m resArr_1 \u001b[39m=\u001b[39m extract_features_1(flow,frame1,frame2)\n\u001b[0;32m     30\u001b[0m resArr_2 \u001b[39m=\u001b[39m extract_features_2(frame2)\n\u001b[0;32m     31\u001b[0m resArr\u001b[39m=\u001b[39mresArr_1\u001b[39m+\u001b[39mresArr_2\n",
      "Cell \u001b[1;32mIn[24], line 29\u001b[0m, in \u001b[0;36mextract_features_1\u001b[1;34m(optical_flow, frame1, frame2, num_bins)\u001b[0m\n\u001b[0;32m     25\u001b[0m hist\u001b[39m.\u001b[39mpop(\u001b[39m3\u001b[39m)\n\u001b[0;32m     26\u001b[0m hist\u001b[39m.\u001b[39mpop(\u001b[39m4\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m h\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(extract_hog_features(of_image))\n\u001b[0;32m     30\u001b[0m sum_hog\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39msum(h)\n\u001b[0;32m     31\u001b[0m mean_hog\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mmean(h)\n",
      "Cell \u001b[1;32mIn[26], line 13\u001b[0m, in \u001b[0;36mextract_hog_features\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     10\u001b[0m cells_per_block \u001b[39m=\u001b[39m (\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[39m# compute the HOG features for the image\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m features \u001b[39m=\u001b[39m hog(image, orientations\u001b[39m=\u001b[39;49morientations, pixels_per_cell\u001b[39m=\u001b[39;49mpixels_per_cell, cells_per_block\u001b[39m=\u001b[39;49mcells_per_block, visualize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, transform_sqrt\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39m# return the features as a 1D NumPy array\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\skimage\\_shared\\utils.py:394\u001b[0m, in \u001b[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m channel_axis \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mchannel_axis\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    393\u001b[0m \u001b[39mif\u001b[39;00m channel_axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 394\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    396\u001b[0m \u001b[39m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[39m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[39m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misscalar(channel_axis):\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\skimage\\_shared\\utils.py:348\u001b[0m, in \u001b[0;36mdeprecate_multichannel_kwarg.__call__.<locals>.fixed_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mchannel_axis\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m convert[kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mmultichannel\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m    347\u001b[0m \u001b[39m# Call the function with the fixed arguments\u001b[39;00m\n\u001b[1;32m--> 348\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python310\\lib\\site-packages\\skimage\\feature\\_hog.py:238\u001b[0m, in \u001b[0;36mhog\u001b[1;34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, transform_sqrt, feature_vector, multichannel, channel_axis)\u001b[0m\n\u001b[0;32m    235\u001b[0m g_row \u001b[39m=\u001b[39m g_row\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    236\u001b[0m g_col \u001b[39m=\u001b[39m g_col\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 238\u001b[0m _hoghistogram\u001b[39m.\u001b[39;49mhog_histograms(g_col, g_row, c_col, c_row, s_col, s_row,\n\u001b[0;32m    239\u001b[0m                              n_cells_col, n_cells_row,\n\u001b[0;32m    240\u001b[0m                              orientations, orientation_histogram)\n\u001b[0;32m    242\u001b[0m \u001b[39m# now compute the histogram for each cell\u001b[39;00m\n\u001b[0;32m    243\u001b[0m hog_image \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the saved Random Forest model\n",
    "model = joblib.load('./cpds/random_forest_model/1.txt')\n",
    "\n",
    "# Define the video capture object\n",
    "cap = cv2.VideoCapture('./cpds/dataset/back_009.mp4')\n",
    "ret, frame1 = cap.read()\n",
    "i = 0\n",
    "count_down = 0\n",
    "count_other = 0\n",
    "    # Loop through the rest of the frames\n",
    "while True:\n",
    "        \n",
    "        # Read the next frame\n",
    "    ret, frame2 = cap.read()\n",
    "        \n",
    "      # If there are no more frames, break out of the loop\n",
    "    if not ret:\n",
    "    \tbreak\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Compute the optical flow using the Farneback method\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    resArr_1 = extract_features_1(flow,frame1,frame2)\n",
    "    resArr_2 = extract_features_2(frame2)\n",
    "    resArr=resArr_1+resArr_2\n",
    "    frame1=frame2\n",
    "    \n",
    "    # Reshape the features into a 2D array\n",
    "    X = np.array(resArr).reshape(1, -1)\n",
    "    \n",
    "    # Use the loaded Random Forest model to predict the label\n",
    "    label = model.predict(X)[0]\n",
    "    # print(type(int(label)))\n",
    "    # Display the label on the frame\n",
    "    #cv2.putText(gray1, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    #cv2.imshow('frame', frame1)\n",
    "    if int(label) == 1:\n",
    "        count_down += 1\n",
    "    elif int(label) == 0:\n",
    "        count_other +=1\n",
    "        \n",
    "    print('Count Down : ',count_down)\n",
    "    print('Count other : ',count_other)\n",
    "    \n",
    "#     if count_back > count_down:\n",
    "#         print(\"back\")\n",
    "#     else:\n",
    "#         print(\"down\")\n",
    "\n",
    "    # Check for quit key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if count_down > count_other:\n",
    "    print(\"Final Result : down\")\n",
    "else:\n",
    "    print(\"Final Result : other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abc2e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Count back :  1\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  2\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  3\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  4\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  5\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  6\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  7\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  8\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  9\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  10\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  11\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  12\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  13\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  14\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  15\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  16\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  17\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  18\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  19\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  20\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  21\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  22\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  23\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  24\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  25\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  26\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  27\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  28\n",
      "Count Down :  0\n",
      "\n",
      "\n",
      "Count back :  29\n",
      "Count Down :  0\n",
      "Final Result : down\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the saved Random Forest model\n",
    "model = joblib.load('./cpds/random_forest_model/1.txt')\n",
    "\n",
    "# Define the video capture object\n",
    "cap = cv2.VideoCapture('./cpds/dataset/down_003.mp4')\n",
    "ret, frame1 = cap.read()\n",
    "i = 0\n",
    "count_down = 0\n",
    "count_other = 0\n",
    "    # Loop through the rest of the frames\n",
    "while True:\n",
    "        \n",
    "        # Read the next frame\n",
    "    ret, frame2 = cap.read()\n",
    "        \n",
    "      # If there are no more frames, break out of the loop\n",
    "    if not ret:\n",
    "    \tbreak\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Compute the optical flow using the Farneback method\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    resArr_1 = extract_features_1(flow,frame1,frame2)\n",
    "    resArr_2 = extract_features_2(frame2)\n",
    "    resArr=resArr_1+resArr_2\n",
    "    frame1=frame2\n",
    "    \n",
    "    # Reshape the features into a 2D array\n",
    "    X = np.array(resArr).reshape(1, -1)\n",
    "    \n",
    "    # Use the loaded Random Forest model to predict the label\n",
    "    label = model.predict(X)[0]\n",
    "    # print(type(int(label)))\n",
    "    # Display the label on the frame\n",
    "    #cv2.putText(gray1, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    #cv2.imshow('frame', frame1)\n",
    "    if int(label) == 1:\n",
    "        count_down += 1\n",
    "    elif int(label) == 0:\n",
    "        count_other +=1\n",
    "        \n",
    "    print('Count back : ',count_down)\n",
    "    print('Count Down : ',count_other)\n",
    "    \n",
    "#     if count_back > count_down:\n",
    "#         print(\"back\")\n",
    "#     else:\n",
    "#         print(\"down\")\n",
    "\n",
    "    # Check for quit key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if count_down > count_other:\n",
    "    print(\"Final Result : down\")\n",
    "else:\n",
    "    print(\"Final Result : other\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1fa163922eb0b3709bbb5d8082b2465c9de796dbaacca80cbaa600e7fff3e4fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
